<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Illusions in the Boardroom by Adrian McPhee — Preview</title>
  <meta name="description" content="AI can now read and reconcile what your organisation says with what your systems do. Read the opening chapters of AI Illusions in the Boardroom by Adrian McPhee.">
  <meta name="author" content="Adrian McPhee">
  <meta property="og:type" content="book">
  <meta property="og:title" content="AI Illusions in the Boardroom by Adrian McPhee">
  <meta property="og:description" content="AI can now read and reconcile what your organisation says with what your systems do. Read the opening chapters free.">
  <meta property="og:image" content="https://simpleisadvanced.com/ai-illusions-in-the-boardroom/og-image.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <link rel="canonical" href="https://simpleisadvanced.com/ai-illusions-in-the-boardroom/">
  <style>
    body { max-width: 42em; margin: 2em auto; padding: 0 1.5em; font-family: Georgia, serif;
           line-height: 1.7; color: #222; background: #fff; }
    h1 { font-family: system-ui, sans-serif; font-size: 1.8em; margin-bottom: 0.2em; }
    h1 + p { color: #666; font-style: italic; margin-top: 0; }
    h2 { font-family: system-ui, sans-serif; font-size: 1.3em; margin-top: 2.5em;
          border-top: 1px solid #e5e5e5; padding-top: 1.5em; }
    h2.part { font-size: 0.85em; text-transform: uppercase; letter-spacing: 0.1em;
              color: #999; border: none; margin-bottom: -1em; padding-top: 2em; }
    h2 a { color: inherit; text-decoration: none; }
    h2 a:hover { color: #c0392b; }
    h3 { font-family: system-ui, sans-serif; font-size: 1.05em; margin-top: 1.5em; }
    p { margin: 0.8em 0; }
    .continue { font-family: system-ui, sans-serif; font-size: 0.9em; }
    .continue a { color: #c0392b; text-decoration: none; }
    .continue a:hover { text-decoration: underline; }
    .header { text-align: center; margin-bottom: 3em; }
    .header img { max-width: 200px; margin-bottom: 1em; }
    .cta { text-align: center; margin: 3em 0; padding: 2em; background: #f9f9f9;
            border-radius: 8px; font-family: system-ui, sans-serif; }
    .cta a { display: inline-block; padding: 0.7em 2em; background: #222; color: #fff;
             text-decoration: none; border-radius: 4px; font-weight: 600; }
    .cta a:hover { background: #444; }
    .banner { position: sticky; top: 0; z-index: 100; background: #222; text-align: center;
               padding: 0.75em 1em; font-family: system-ui, sans-serif; font-size: 0.9em;
               margin: -2em -1.5em 2em; }
    .banner a { color: #fff; text-decoration: none; font-weight: 500; }
    .banner a:hover { text-decoration: underline; }
    footer { text-align: center; color: #999; font-size: 0.85em; margin-top: 3em;
             padding-top: 1.5em; border-top: 1px solid #e5e5e5; }
  </style>
</head>
<body>
  <div class="banner">
    <a href="./">Read in the interactive reader &rarr;</a>
  </div>

  <div class="header">
    <img src="cover.png" alt="AI Illusions in the Boardroom">
    <h1>AI Illusions in the Boardroom</h1>
    <p>What happens when machines can read what you say alongside what your systems do?</p>
    <p style="font-style: normal; font-size: 0.9em;">Adrian McPhee</p>
  </div>

<section id="ch-0">
<h2><a href="./?ch=0">Introduction</a></h2>
<p>By now, it is clear that AI can generate content. It drafts strategy documents, summarises board packs, analyses contracts, explores financial models, generates production code. Most executives use it daily. This book is not about that capability.</p>
<p>It is about the ability of AI to read and reconcile, and the tremendous effect this is set to have on competition, operating models, and the people working inside them.</p>
<p>When a machine can read what you say alongside what your systems do, the gap between narrative and reality becomes measurable. A strategy document can be compared against the code that must implement it. An architecture reference model can be compared against what is actually running. A budget line can be compared against the operational outcomes it was meant to produce. A portfolio label can be compared against the services that supposedly comprise it. An investment case can be compared against the incident costs it was meant to prevent.</p>
<p>These comparisons are not hypothetical. They are available today, at negligible cost, to any organisation willing to point an AI system at its own artefacts and ask a simple question: does what we say match what we do?</p>
<p>Once these artefacts can be read together, the organisation’s claims become testable. Structural honesty becomes measurable rather than aspirational.</p>
<p>For most organisations, the answer is no. Not because the people inside them are dishonest, but because the structures they operate within have made honesty expensive and vagueness cheap for more than a decade.</p>
<p>This book uses a specific term: software-dependent corporate. It refers to large, established organisations whose products and operations depend critically on software, but whose governance structures were designed for a world in which software was a support function.</p>
<p>Banks, insurers, retailers, logistics firms, airlines, public sector bodies, and older companies that describe themselves as technology companies but still operate with inherited governance assumptions all fall into this category. These organisations are not pre-software. They have had software for decades. What they have not adapted to is the shift that occurred between roughly 2008 and 2012, when software stopped being infrastructure and became the primary medium through which these companies create and deliver value.</p>
<p>By 2012, the structural change was complete: these organisations needed to become software companies. They hired engineers by the hundreds, adopted continuous delivery, and launched digital transformation programmes. The governance structures, the budget cycles, the HR frameworks, and the executive mental models stayed where they were. The technology changed. The power structures did not. The misalignment has been compounding ever since.</p>
<p>The most reliable diagnostic is linguistic. If your organisation talks about “the business” as a group of people who are not engineers, your organisation is a software-dependent corporate. If engineers are considered to work in the business by default, it probably is not. Once that split exists, the gap between what the organisation says and what the system does becomes self-sustaining.</p>
<p>Software-dependent corporates evolved structures that separate “the business” from engineering, producing representations with no operational counterpart: narratives that replace reality, portfolio labels with no executable boundary, avoidant architecture, processes that were never written down. These are not failures of intelligence. They are coping mechanisms. They are how intelligent people remain functional inside structures that will not let them do real work. I have watched this pattern repeat in every large organisation I have worked in, across fintech, retail, and mobility, and the consistency is itself diagnostic.</p>
<p>Since that shift, these organisations have survived the misalignment by making reality expensive and vagueness cheap. Understanding the system required meetings. Reconciling strategy required interpretation. Connecting cost to value required politics. The dysfunction was real, but it was survivable. Human synthesis could bridge the gap, expensively, and market position provided insulation.</p>
<p>For two decades, organisations absorbed structural deficits socially: through meetings, translation roles, governance ritual, and institutional memory. In every one of these organisations, someone carried the real system in her head: she knew which architecture diagrams were fiction, which products did not exist as coherent systems, which processes survived only as institutional memory. She spent her weeks translating between marketing, operations, finance, product, architecture, and engineering, reconciling artefacts that the organisation’s structure had separated and no one had authority to rejoin, building nothing, deciding nothing, holding the organisation together. It was inefficient, fragile, and entirely dependent on the continued presence and goodwill of people like her. It held, until AI made the same synthesis available at negligible cost.</p>
<p>There is a simple test for any software-dependent corporate. If an AI system reads your strategy documents, your architecture models, your process descriptions, and your code together, will the synthesis converge on something coherent? Or will it collapse into contradiction?</p>
<p>For most organisations, it collapses. The strategy describes interfaces the code does not implement. The architecture reference model describes boundaries the system does not observe. The portfolio contains products that no engineer can map to a coherent set of services. The investment case omits costs the incident log makes visible. Each gap has been survivable individually for years. What changes is the cost of knowing. Reconciliation that once required weeks of consulting time and political capital is now available continuously, cheaply, and without political filtering.</p>
<p>Cheap synthesis does not force truth. It forces a choice: pay the rising cost of suppression, or authorise the structural changes that make truth useful. This book is about that choice.</p>
<p>Part I, When Machines Read, introduces the inversion. What changes is not what AI can produce, but what it can reveal.</p>
<p>Part II, The Illusion Was Rational, shows how software-dependent corporates produce and stabilise representations that do not correspond to the systems they describe. The illusions are not failures of intelligence. They are coping mechanisms with a cost structure.</p>
<p>Part III, Capital Mispricing and Structural Risk, traces the consequences. When the gap becomes measurable, capital allocation, coordination costs, talent retention, and regulatory exposure are all repriced.</p>
<p>Part IV, Structural Correction, describes the specific structural commitments that make an organisation machine-readable: process ownership, contracts, data as published product, and the executive decisions that authorise them.</p>
<p>The conclusion presents the choice: accelerate narrative production, or reconcile reality continuously. The two paths are incompatible without structural change.</p>
<p>The vignettes throughout this book are illustrative. They are composited and fictionalised to represent structural patterns the author has observed across consulting engagements in financial services, retail, logistics, and media. Details, including industry, geography, headcount, individual roles, and financial figures, have been invented or altered. No vignette describes a specific organisation. The patterns are real. The examples are not.</p>
</section>
<h2 class="part">When Machines Read</h2>
<section id="ch-1">
<h2><a href="./?ch=1">Chapter 1: AI as the Unforgiving Reader</a></h2>
<p>A large European telecoms operator decides to pilot an AI assistant for its technology leadership. The brief is modest: given access to the company’s strategy documents, architecture diagrams, and code, the assistant should produce a summary of the organisation’s technology landscape and its alignment with stated strategic priorities.</p>
<p>The CTO is supportive. The experiment is sanctioned. A small team feeds the assistant the relevant artefacts: the annual strategy deck, the technology vision document, the architecture reference model (last updated fourteen months ago), the current service catalogue, and read access to the primary code repositories.</p>
<p>The assistant produces a twelve-page synthesis that is calm, precise, and devastating.</p>
<p>It notes that the strategy deck identifies “digital self-service for enterprise customers” as a top-three priority, but that only two of forty-seven services have any self-service provisioning logic, and both are experimental prototypes with no production traffic. It observes that the architecture reference model describes eight distinct areas of business responsibility, each meant to own its own data, but that the actual system follows a different structure: one organised around legacy databases rather than business domains. It identifies fourteen services that share a single database, contradicting the reference model’s assertion of independent ownership.</p>
<p>The summary does not editorialise. It reconciles what the organisation says with what the organisation does, and lists the contradictions.</p>
<p>The CTO reads the summary. She recognises every finding. None of it is new to her. What is new is the vertigo of seeing it confirmed in someone else’s words, after years of carrying it alone. But it is written down in a single document, produced in hours rather than months, and cannot be dismissed as one person’s opinion.</p>
<p>She forwards the summary to the CEO. The CEO’s response arrives within a day. He does not dispute the findings. He asks that the summary not be shared further, because “the board narrative is different, and we are not ready to reconcile.”</p>
<p>The CTO proposes a compromise: reconcile one business domain, network provisioning, as a limited pilot. The CEO declines. The pilot would produce artefacts that contradict the strategy deck submitted to the board three weeks from now. The objection is not that reconciliation is premature. It is that reconciliation would produce evidence.</p>
<p>The summary is saved in a folder with restricted access. The AI pilot is described as “promising but premature.” The strategy deck is presented to the board the following month, unchanged. It describes an organisation that the synthesis showed does not exist.</p>
<p>The CEO’s decision was not to defer reconciliation but to prevent it. That distinction matters. The decision preserved narrative coherence at the expense of reconciled evidence.</p>
<p>Artificial intelligence is most commonly discussed as a creator: writing code, drafting documents, generating answers, producing images. Most enterprise AI investment targets this capability. The rationale is understandable: these are real productivity gains. They are also the less important use of the technology.</p>
<p>AI’s real power in organisations is not that it produces artefacts but that it reads them. It reads without fatigue, without respect for hierarchy, narrative confidence, or institutional memory. It does not know who wrote a document or how many people approved it. It only cares whether what exists corresponds.</p>
<p>Most organisations get this distinction backwards. The generator accelerates the part that was never the bottleneck. Writing code was never the hard part of building software. Design is: deciding what to build, where the responsibilities lie, how the pieces interact, and what happens when they fail. These decisions depend on clear business processes, explicit ownership, and precise descriptions of how value is created. No code assistant helps with this, because the inputs are not code. They are organisational structure, business logic, and customer journeys, and in most software-dependent corporates, these inputs do not exist in a form that any tool, human or machine, can reason about reliably.</p>
<p>The generator also reinforces a comfortable assumption: that AI is a tool that works for people inside the existing organisational structure, enhancing their existing capabilities. This does not threaten anyone’s role. It does not challenge any power structure. The reader does both. It helps organisations see themselves clearly, which is why most organisations deploy the generator first and the reader never.</p>
<p>When AI is used as a reader, as a system that continuously reconciles what the organisation says with what it does, the implications are structural. The reader does not produce new content. It produces accountability. It takes artefacts that were designed to exist independently and reads them together, surfacing contradictions that the organisation has been maintaining socially.</p>
<p>Consider the telecoms vignette. The strategy deck, the architecture model, the service catalogue, and the code had all existed for years. They had been reviewed by different people at different times for different purposes. No one had read them together and asked: are these consistent? The AI did not discover anything the CTO did not already know. It enumerated what she knew in a form that could not be dismissed as opinion or interpreted away through social negotiation.</p>
<p>The reader does this across multiple domains simultaneously.</p>
<p>Strategy versus code. The AI parses the strategy for testable claims. “API-first design” is a testable claim. “Drive digital transformation” is not. For each testable claim, it examines the code for evidence. The output is not a judgement. It is an inventory: 47 services, 312 connections between them, of which 119 (38\</p>
<p>The AI gets things wrong, and the kinds of errors are instructive. It inflates the service count by treating internal components as separate systems. It counts monitoring traffic as real communication, which is technically correct and analytically useless. It cannot distinguish between a workaround that persists because no one has fixed it and a design choice that persists because someone decided it was correct. Context, intent, and history are invisible to the reader. Structure is not.</p>
<p>These are not edge cases. They are the permanent boundary of what machine reading can do. A routing rule that bypasses the defined process may be a bug, a workaround that prevents a worse failure, or a design choice that was never documented. The AI cannot tell the difference. The human triage step is not a temporary cost of early adoption. It is permanent. Organisations that expect the machine to replace judgement will produce reconciliation reports that are precise, comprehensive, and wrong in exactly the ways that matter.</p>
<p>There is a subtler failure mode. Once reconciliation is continuous, people will learn to write artefacts that pass the audit rather than artefacts that describe the truth. Process definitions will converge on what the code does rather than what the process should do. Formal compliance will replace substantive accuracy. The tool audits consistency, not quality. Quality still requires ownership.</p>
<p>The first reconciliation requires human triage. The second cycle is better, because the triage narrows the scope. By the third, the error rate is low enough that the output is decision-quality.</p>
<p>Process definition versus system behaviour. When an organisation has explicit process definitions and code, AI can compare the two. Take a claims process: “when a claim is submitted, the system validates required fields, assigns a claim number, and routes to the appropriate assessor queue based on claim type and value.” The AI can verify whether the code actually does this.</p>
<p>The results are often revealing. The process definition says claims are routed by type and value. The code shows that routing also depends on an undocumented field set by a legacy system. The process definition says validation occurs at submission. The code shows that some fields are validated after the fact, and failures are logged but not surfaced to the submitter. The process definition does not mention a retry mechanism. The code has one, and it has been silently masking data quality issues for eighteen months. These are the kinds of discoveries that organisations make when they first subject their stated processes to machine reading.</p>
<p>Architecture diagrams versus what is actually running. The AI reads an architecture reference model and compares it to the systems that are actually deployed. The discrepancies are always present: shared databases where the diagram shows independence, direct calls between systems where it shows clean separation, services organised around technical convenience where it describes business domains.</p>
<p>Business plan versus code. The business plan promises contractor-ready specifications. The system has no measurement infrastructure. The business plan projects affiliate revenue. The tracking is not wired to partner systems. These gaps are not visible in ticket systems or strategy reviews. They become visible instantly when an AI reads both artefacts together.</p>
<p>The preceding examples describe what reconciliation reveals. This section shows what it looks like.</p>
<p>Consider a claims management process at a mid-sized European insurer. Suppose the team responsible has described its process in structured terms: a definition precise enough for software to parse. The specific format matters less than the commitment it represents.</p>
<p>The definition lists eight states a claim can occupy: submitted, under review, documents requested, assessed, approved, declined, paid, and closed. It specifies the transitions between them, the triggers that cause each transition, and the failure modes. It states, for instance, that when a claim moves from under review to documents requested, a five-business-day timeout applies, and if the timeout is exceeded, the case escalates to the team lead. Every state, every transition, and every exception is explicit and versioned.</p>
<p>The AI reader consumes this definition alongside the code that implements the claims process. It produces a reconciliation report. An illustrative first report might look approximately like this:</p>
<p>Reconciliation: claims management process v1.2 against the running system</p>
<p>Convergent (definition matches implementation):</p>
<p>The transition from submitted to under review is implemented as described. Automatic triage validates required fields before the claim advances. The transition from under review to assessed also matches: the assessor’s completion of the review triggers the state change as defined.</p>
<p>Divergent (definition does not match implementation):</p>
<p>The timeout for requesting documents is defined as five business days. The system counts calendar days, not business days. Claims submitted on Wednesday that require documents will timeout on Monday (five calendar days) rather than the following Wednesday (five business days). Impact: premature escalation of approximately 15\</p>
<p>The escalation for overdue document requests routes to a Slack channel with 47 members rather than to the team lead directly. Average response time to escalations in this channel is 6.2 hours. The process definition implies direct escalation.</p>
<p>Undefined (implemented but absent from definition):</p>
<p>A re-review step exists in the system: when an assessor sends a claim back for further review, it returns to the under review state. This step is not in the process definition. It is used approximately 40 times per month. Without it, re-reviewed claims would need to be declined and resubmitted.</p>
<p>Unimplemented (defined but not found in code):</p>
<p>The escalation for overdue documents is defined in the process, but the system silently exempts claims valued below € 500. This exemption exists nowhere in the process definition.</p>
<p>The reconciliation took eleven minutes. A consulting engagement performing the same analysis through interviews and document review would take two to four weeks and would be unlikely to identify the business-day versus calendar-day discrepancy, because that discrepancy lives at the intersection of a process rule, a scheduling configuration, and a date calculation: three artefacts that no single interviewee would hold in mind simultaneously.</p>
<p>The reconciliation is only possible because the process definition exists as a structured, machine-readable artefact. Without it, the AI reader can describe what the code does, but it cannot identify where the code diverges from intent, because intent was never written down. The first cycle for any organisation is noisy. By the third or fourth weekly cycle the useful findings far outweigh the noise, and the reconciliation functions as a genuine governance instrument: a continuous audit of whether the organisation’s processes behave as described.</p>
<p>The reader’s power is not analytical insight. It is the production of accountability by enumerating contradictions.</p>
<p>In organisations where reality has been mediated through layers of representation, humans perform an enormous amount of interpretive labour. They bridge gaps between strategy and execution with context, intuition, and social negotiation. They absorb contradictions implicitly. They carry exceptions in their heads. They know that the architecture diagram is wrong but act as though it is right, because acting otherwise would require a conversation nobody wants to have.</p>
<p>This labour is invisible and unpaid. It is also what allows illusions of work to persist. When the organisation’s descriptions are too vague for the AI to reason about, it fills gaps with inference, not because the technology is immature but because the inputs are empty. The parallel between human and machine interpretation is instructive. Both have the same root cause: insufficient precise information. The difference is that human gap-filling is invisible, hiding inside institutional knowledge and social negotiation, while AI gap-filling is visible and embarrassing. This visibility is the reader’s gift to the organisation. It makes the cost of vagueness undeniable.</p>
<p>When the AI produces a list of contradictions, the organisation can no longer claim ignorance. The contradictions are documented, enumerated, and attributed. Someone must respond.</p>
<p>The response is revealing. The CEO in the telecoms vignette did not dispute the findings. He suppressed them. He asked that the summary not be shared further. This is rational behaviour. The board narrative was different, and closing the gap would have required confronting structural problems that the organisation had been absorbing socially for years.</p>
<p>There is a subtler response: constraining the reader rather than confronting it. AI access is limited to sanitised artefacts. Outputs are reviewed before circulation. The synthesis is filtered through the same narrative layer it was meant to bypass. Vendor incentives reinforce this: enterprise AI products are designed to complement existing workflows, not to challenge them. Regulatory caution provides further cover. Data governance, model risk, and compliance concerns are real, but they are also convenient reasons to keep the auditor on a short leash. The technology is neutral. Its deployment never is.</p>
<p>The suppression response is rational but not stable. It can be sustained when the cost of reconciliation exceeds the cost of suppression. Cheap synthesis changes the ratio.</p>
<p>When synthesis required a twelve-week consulting engagement, suppression was easy. The engagement happened once, produced a report, and the report could be filed. The gap between engagements allowed the organisation to absorb the findings without changing anything.</p>
<p>When synthesis is continuous, suppression becomes expensive. The AI reader produces a new synthesis every week. Each cycle surfaces the same contradictions, plus any new ones that have accumulated. The organisation must actively manage the output: filtering it, restricting access, explaining why findings are not being acted on. The effort required to maintain the illusion rises while the cost of replacing it with clarity falls.</p>
<p>The dynamic is already observable, driven by the reduced cost of verification.</p>
<p>For boards, the implication is direct. When synthesis is expensive, the board has no alternative to governing through unverified representations. When it is cheap, the board has a choice. It can demand artefacts that have been reconciled against the system before they arrive at the boardroom. It can require that the contradictions are surfaced, not smoothed. Whether the board makes this demand depends on whether it prefers comfort or clarity.</p>
<p>The constraint that the reader surfaces is structural, not technical. The technology is available today. The question is whether the organisation is willing to let it read.</p>
</section>
<section id="ch-2">
<h2><a href="./?ch=2">Chapter 2: When AI Writes the Illusion</a></h2>
<p>The quarterly board pack is due in three days. The strategy team has been preparing it for two weeks, but the technology section is still weak. The CTO’s team has submitted their update: accurate, detailed, and unreadable. Twelve pages of service dependencies, incident summaries, and migration status. The board will not engage with it.</p>
<p>So the chief of staff feeds the CTO’s update into an AI assistant, along with the company’s strategy document and last quarter’s board narrative. The prompt is simple: produce a two-page technology summary that connects the current state of the technology estate to the company’s strategic priorities, suitable for a board audience.</p>
<p>The result is impressive. The summary connects the migration of three services to a strategic priority around customer self-service. It cites a 23\</p>
<p>The CTO reads it carefully.</p>
<p>The 23\</p>
<p>Every fact in the summary is individually defensible. The synthesis is internally coherent but externally unverified.</p>
<p>The CTO marks up three corrections, sends it back, and books a meeting to review them before the board deadline, knowing it will not survive the week. It is rescheduled once, then dropped. The board reads the uncorrected summary. The CEO notes that the technology narrative “finally feels aligned with strategy.” Nobody asks whether the alignment is real.</p>
<p>The previous chapter described AI as an unforgiving reader. This chapter describes its counterpart: AI as a fluent writer of organisational narrative. Most organisations discover the writer first, and the writer is the more dangerous of the two.</p>
<p>AI-generated narrative is dangerous not because it is false but because it is plausible.</p>
<p>A human writing a strategy update must work from what she knows. Her knowledge is incomplete, her time is limited, and her prose reflects both. The gaps are visible. The vagueness is detectable. A reader with system knowledge can see where the narrative departs from reality, because the departure is clumsy.</p>
<p>An AI writing the same update works from whatever it is given. If the inputs include a strategy document and a set of metrics, the AI will find connections between them, even if the connections are spurious. It will use architectural vocabulary correctly. It will cite numbers accurately. It will produce a synthesis that reads as though someone with deep understanding wrote it.</p>
<p>The AI does not have deep understanding. It has inputs. If the inputs are disconnected from reality, the output will be disconnected from reality. The difference is that the output will not look disconnected. It will look coherent, authoritative, and aligned.</p>
<p>AI-generated narrative removes the friction that once made illusion detectable. The person who prompts the AI may not know whether the output is grounded. The executive who reads it almost certainly does not. The narrative becomes self-reinforcing: it sounds precise, therefore it is treated as precise, therefore nobody checks whether it corresponds to anything real. The organisation has not become clearer. It has become more confidently wrong.</p>
<p>AI makes narrative cheap, which deepens the problem.</p>
<p>In the old model, producing organisational narrative required effort. A strategy deck took weeks. A board pack consumed days. The expense acted as a natural constraint. The effort of production forced at least some engagement with the underlying reality.</p>
<p>AI removes this constraint. Narrative becomes abundant. Strategy updates can be generated weekly instead of quarterly. Status reports can be produced for every team rather than every division. Product documents can be drafted for every idea rather than every commitment. The organisation generates more narrative, more frequently, with less human effort.</p>
<p>The adversarial case, that AI generates better illusion, appears to undermine the argument of this book. If AI makes pretence more convincing, how can AI also be the force that destabilises it?</p>
<p>The answer lies in an asymmetry between generation and reading.</p>
<p>AI-as-generator operates on narrative inputs. It reads documents, metrics, and descriptions. It produces a synthesis of what those documents say. It cannot check whether they are true. It has no independent access to the system. It works with representations, and if the representations are wrong, the output is wrong. Fluently, convincingly, dangerously wrong.</p>
<p>AI-as-reader operates on artefacts that bind. It reads the code. It reads what is actually deployed and running. It reads the process definitions wired into the running system. It compares what the organisation claims with what the system does. It cannot be fooled by better prose, because it is not reading the prose. It is reading the system.</p>
<p>The asymmetry is decisive. The generator can produce a board summary claiming the platform migration is 70\</p>
<p>No amount of polished narrative survives contact with a system reader. The better the narrative, the more embarrassing the contradiction when the reader surfaces it.</p>
<p>There is a predictable misreading here. The solution is not better documentation with an AI layer on top. The reader only has force when the artefacts it reads are binding, when deviation carries consequence and someone is accountable for resolving it. Without structural ownership, AI does not expose illusion. It industrialises it.</p>
<p>Every software-dependent corporate now faces a fork between these two uses.</p>
<p>One path uses AI to write. To generate better narratives, smoother updates, more convincing decks. This path is easy, immediately rewarding, and politically safe. It threatens no power structure. It challenges no assumption. It makes the existing model more efficient.</p>
<p>The other path uses AI to read. To compare strategy with systems, process definitions with code, cost allocation with value creation. This path is uncomfortable, politically dangerous, and structurally transformative. It threatens everyone whose authority depends on controlling the narrative rather than understanding the system.</p>
<p>Most organisations will try to do both. They will discover that the two uses are not complementary. They are contradictory.</p>
<p>Consider what happens in practice. A product team uses an AI assistant to draft a product requirements document for a new self-service claims feature. The PRD is fluent and specific: it describes user flows, defines acceptance criteria, and references the existing claims architecture by name. It takes thirty minutes to produce. The team is pleased. The PRD is circulated.</p>
<p>The following week, an engineering lead runs the organisation’s AI synthesis against the code alongside the new document. The synthesis flags three problems. The “existing claims architecture” the PRD references was decommissioned six months ago; the current implementation uses a different service with different data contracts. Two of the described user flows require access to a customer record service that the claims team does not own and has no contract with. The acceptance criteria reference a response time SLA that no system in the current architecture can meet.</p>
<p>The document sounded precise. The system is not. The AI wrote a convincing description of something that cannot be built as described, and the AI reader caught it in minutes.</p>
<p>The organisation now has a choice: fix the document to match reality, or suppress the synthesis and ship the document as written. The first is uncomfortable. The second is expensive. Both reveal that the two uses of AI, writing and reading, pull in opposite directions unless the writing is grounded in the same reality the reader inspects.</p>
<p>The constraint is that the fork is a governance choice, not a technology choice. It asks whether you want AI to help you describe reality or to help you avoid it. The economics of each path diverge rapidly, as the next chapter examines.</p>
</section>
<section id="ch-3">
<h2><a href="./?ch=3">Chapter 3: When Clarity Becomes Cheaper Than Pretence</a></h2>
<p>The CTO of a mid-sized European insurer commissions a quarterly consulting engagement to reconcile the technology estate against the strategy. The engagement takes eight weeks and costs € 180,000. The consultants produce an accurate report. Before the findings reach the board, the CTO reviews them and softens the language. Three months later, the same gaps persist. The next engagement produces the same findings.</p>
<p>The CTO observes that the cost of knowing has remained constant while the gap has widened. She runs the same analysis using AI synthesis. It takes two days. The output is comparable. She runs it again the following week. The cost of knowing has collapsed. The cost of not knowing has not changed. The asymmetry has reversed.</p>
<p>For most of the history of large organisations, clarity has been expensive.</p>
<p>Understanding how a system actually worked required time, access, and experience that could not be short-circuited. The people who could synthesise strategy, architecture, and operational reality were rare, costly, and fragile: when they left, their knowledge left with them.</p>
<p>This was a rational response to a real cost structure, not a pathology. When synthesis is expensive, you invest in the people who can do it and tolerate the risk that any of them might leave tomorrow and take a piece of the organisation’s self-knowledge with them.</p>
<p>Pretence, by contrast, was cheap. Vague plans could be approved quickly. Ambiguous ownership avoided conflict. Narrative coherence could be maintained through ritual and repetition. The cost of maintaining the illusion was lower than the cost of replacing it with truth.</p>
<p>Software-dependent corporates evolved to exploit this asymmetry. They became expert at managing the gap between what was said and what was real. They built entire functions, programme management, portfolio governance, strategy offices, transformation teams, whose purpose was to maintain coherence at the narrative level without requiring coherence at the system level.</p>
<p>The Introduction described what synthesis costs: gathering the right people, with the right access, in the right room, at a cost measured in weeks and political capital. AI collapses that cost. It reads everything it is given in parallel, produces a synthesis in hours rather than weeks, and can be run continuously rather than annually.</p>
<p>Cheap synthesis only has structural force when someone is accountable for the result. If ownership remains diffuse, AI produces insight without consequence. The contradictions are visible. No one is obligated to resolve them.</p>
<p>When clarity was expensive, organisations optimised for impression management: rewarding ambiguity, tolerating contradiction, valuing the appearance of understanding over understanding itself. When clarity is cheap, these behaviours become liabilities.</p>
<p>The shift is from lagging to leading. In the current model, the organisation discovers an unmanaged dependency through an incident, an undocumented process through a regulatory inquiry, a context gap through a departure. Each signal arrives after the damage. Continuous synthesis inverts this. Contradictions surface when they are introduced, not when they cause damage. The organisation that operates through artefacts does not govern more carefully. It sees earlier.</p>
<p>Ambiguous ownership gains a number. When an AI reader reports that a particular process spans four teams with no single owner, and that this is correlated with an incident rate three times higher than the organisational average, the ambiguity can no longer be managed quietly. It has a number attached to it.</p>
<p>Unjustified decisions lose cover. When the CFO says “the numbers don’t support this investment,” and the AI reader shows that the investment’s absence has caused € 2 million in incident costs over eighteen months, the CFO’s position weakens. Not because the CFO is wrong about the numbers, but because the numbers are incomplete, and the AI has made the incompleteness visible.</p>
<p>Organisations that adapt experience a shift. Meetings become shorter because fewer assumptions need to be negotiated. Documents become shorter because they are forced to be precise. Autonomy increases because boundaries are clear. Coordination costs fall because coordination is only necessary when boundaries are ambiguous.</p>
<p>Organisations that resist attempt to insulate existing structures from exposure. AI is constrained to narrow use cases that do not challenge the organisational model: code generation, documentation drafts, chatbot experiments. The cost of pretence rises as more effort is required to maintain the illusion in the presence of a tool that sees through it. The organisation finds itself spending increasing resources on managing AI rather than benefiting from it.</p>
<p>The neutralisation tactics are predictable. Sanitising inputs: feeding AI only the artefacts that confirm the narrative. Constraining outputs: requiring human review of synthesis before circulation. Redefining terms: calling existing teams “autonomous” without changing their authority. Adding governance to contracts: creating review boards around the mechanism that was designed to replace review boards. Each tactic preserves the appearance of adoption while preventing the structural consequences. Each is detectable by the reader itself, which is why the reader must have unfiltered access to be effective.</p>
<p>Selection pressure appears, not from management mandate, but from observable performance. The clear team delivers more, with less effort, and with higher morale. Other teams notice. Talented engineers request transfers. New hires prefer the clear team. The dynamics become self-reinforcing. Clarity attracts capability. Capability produces results. Results attract attention. Attention creates pressure for the rest of the organisation to follow.</p>
<p>The same dynamic operates between organisations. Consider two insurers of similar scale, same market, same regulation. One makes its core processes machine-readable: autonomous units, versioned contracts, weekly AI synthesis. The other adopts AI as a productivity tool: copilots, chatbots, content generation. The underlying structure remains unchanged.</p>
<p>After three years, the gap is structural. One adapts in weeks. The other adapts in quarters, if at all. The difference compounds silently in the cost of every decision, every incident, every missed change.</p>
<p>This comparison assumes that the resisting organisation will eventually lose. That assumption deserves scrutiny.</p>
<p>In regulated industries with high switching costs, structural inefficiency can persist for decades. An insurer that suppresses clarity does not need to be excellent. It needs to be solvent, compliant, and politically stable. If its customers face significant friction in switching, through long-term policies, embedded group schemes, or regulatory lock-in through approved provider lists, if its regulators evaluate it on capital adequacy and claims ratios rather than internal coherence, and if its competitors operate with the same inherited structures, the selection pressure may not be lethal. It may not even be uncomfortable.</p>
<p>Suppression in this context is not passive. It is active and sophisticated. AI tools are deployed, but constrained to operate on sanitised artefacts: approved process documents rather than the actual code, curated data feeds rather than raw operational data. When an AI system produces an uncomfortable finding, the response is not to act on it but to adjust the inputs. The AI reader is given less to read. Outputs are filtered through the same narrative layer they were designed to bypass. These are not signs of failure to adapt. They are signs of successful defence of the current power structure. The people who benefit from opacity are not stupid. They understand, often better than the technologists advocating for change, what transparency would cost them.</p>
<p>There is a reasonable objection to this analysis. The coordination overhead described in this book is not a bug. It is a feature. Ambiguity enables profitable flexibility. The programme manager who negotiates across twelve teams is not wasting time. She is maintaining optionality: the capacity to reframe priorities, absorb contradictions, and keep multiple commitments alive simultaneously without forcing premature decisions. The coordination tax funds this optionality. The meetings, the translation layers, the governance rituals are the price the organisation pays for the ability to change direction without confronting the full cost of each change.</p>
<p>The argument had force when software was a cost centre. When software mediates every customer interaction, every regulatory obligation, and every revenue-generating process, the flexibility that ambiguity once purchased now purchases delay. The programme manager who maintains twelve dependencies is not preserving optionality. She is preserving a structure in which no one can act. The governance ritual that once allowed the organisation to absorb contradiction now prevents it from resolving contradiction. The cost has not changed. What the cost buys has.</p>
<p>The durable equilibrium breaks under specific conditions, and the specifics matter more than the abstraction.</p>
<p>Regulatory mandates are already moving. DORA and operational resilience frameworks require firms to demonstrate traceable, end-to-end understanding of critical business processes. An organisation that governs through narrative cannot produce this evidence cheaply. It must reconstruct the process from institutional memory every time a regulator asks.</p>
<p>Private equity acquirers expose the gap from a different angle. When a PE firm’s operating partners run technical due diligence, they are asking Peter’s question from Chapter 5 at enterprise scale: which capabilities described in the investment thesis correspond to coherent system boundaries, and which are portfolio labels? The answer reprices the asset.</p>
<p>Talent flight forces it from below. Experienced engineers who carry irreplaceable context leave for organisations where reality is valued over narrative. Each departure destroys institutional knowledge that was never written down.</p>
<p>A competitor deploying AI synthesis forces it from outside. When a structurally coherent competitor reconciles its strategy against its systems continuously, the performance gap becomes visible to the market in response times, in product velocity, in the cost of regulatory compliance. The advantage compounds.</p>
<p>Absent these conditions, the equilibrium holds. The organisation pays the ongoing cost of incoherence, a cost it has been paying for years and has learned to absorb, and directs its political energy towards ensuring that the cost remains invisible.</p>
<p>The honest position is this: this book cannot promise that clarity wins in every market on every timeline.</p>
<p>The decision is not symmetric. An organisation that adapts early and discovers the equilibrium persists has still reduced its operating costs, improved its retention, and built structural capability that compounds independently of competitive pressure. An organisation that delays and discovers the equilibrium has broken faces a structural deficit that cannot be closed by purchasing the same tools. The tools require structural preconditions that take years to establish. The gap widens.</p>
<p>Early adaptation that proves premature still pays for itself. Late adaptation that proves necessary starts years behind. This asymmetry is the argument, not a prediction of which competitors will move first.</p>
<p>The constraint is economic, not technological. The tools exist, and the remaining obstacle is not capability but willingness.</p>
</section>
<h2 class="part">The Illusion Was Rational</h2>
<section id="ch-4">
<h2><a href="./?ch=4">Chapter 4: The Board Narrative and the System</a></h2>
<p>The CEO of a mid-sized European insurer, approximately 4,000 employees with a core policy administration platform dating from 2007, is eighteen months into her tenure. She has done what a competent CEO should do. She hired a respected CTO from a digital-native company. She funded a three-year technology modernisation programme at € 40 million, more than the board wanted, less than the CTO asked for, a reasonable compromise. She approved a new organisational structure: product-aligned teams, a platform group, an architecture function. She attended the first two quarterly reviews personally, to signal commitment.</p>
<p>The strategy is coherent. The CTO is capable. The funding is real. The board is supportive.</p>
<p>Two years in, the core measures she cares about have not moved: time to market for new products, operational cost per policy, customer retention. Two major initiatives have been quietly descoped. The CTO reports progress. The CFO reports cost. Neither report contradicts the other. Neither explains why the organisation feels no different.</p>
<p class="continue"><a href="./?ch=4">Continue reading →</a></p>
</section>
<section id="ch-5">
<h2><a href="./?ch=5">Chapter 5: Portfolio Labels That Do Not Exist in Code</a></h2>
<p>The product review is held monthly. Each product owner presents to the CPO and a panel of senior stakeholders. Richard, the product owner for “Customer Engagement,” presents third. His slides show a funnel, a set of KPIs, and a roadmap with six items colour-coded by quarter. The presentation is fluent, the narrative confident. Customer Engagement is growing. Retention is improving. The team has delivered twelve features this quarter.</p>
<p>Then an enterprise architect named Peter asks a question. “Which services comprise Customer Engagement?”</p>
<p>The room shifts. Richard begins to answer, then pauses. Customer Engagement, it turns out, is not a system. It is a label applied to a collection of features that span four different services, maintained by three different teams, two of which report into a different product area. The notification service is shared with Operations. The recommendation engine sits inside a legacy monolith nominally owned by Transactions. The analytics pipeline runs on infrastructure maintained by a platform team that was recently reorganised.</p>
<p class="continue"><a href="./?ch=5">Continue reading →</a></p>
</section>
<section id="ch-6">
<h2><a href="./?ch=6">Chapter 6: Architecture as False Abstraction</a></h2>
<p>In organisations of this kind, architecture is often presented as a source of control. Diagrams promise clarity and reference models suggest foresight. In practice, much of this architectural activity exists to avoid accountability rather than to produce it.</p>
<p>Architects are not the problem. Most enterprise architects are deeply skilled, analytically rigorous, and genuinely frustrated by the gap between what they design and what the organisation builds. Architecture, in these organisations, is asked to perform a task it cannot fulfil: to impose coherence without changing the underlying structure of responsibility.</p>
<p>The distinction that matters is between advisory architecture and binding architecture.</p>
<p class="continue"><a href="./?ch=6">Continue reading →</a></p>
</section>
<section id="ch-7">
<h2><a href="./?ch=7">Chapter 7: Splitting the System Without Splitting the Problem</a></h2>
<p>A logistics company needs to add a new delivery status, “held at customs,” to the tracking flow visible to customers. The status already exists in the customs clearance system. It needs to propagate to the shipment tracking service, which feeds the customer-facing portal.</p>
<p>In a system with real boundaries and owned contracts, this is two days of work. One team adds the status to its published event contract. The consuming team reads the new event and renders it in the portal. Both teams can do this independently, on their own release schedules, with a versioned contract governing the interaction.</p>
<p>In this organisation, none of that applies.</p>
<p>The shipment tracking service does not own its own data model. It reads from a shared database maintained by a “data platform” team. The data platform team has a change request process that requires approval from three service owners, because any change to the database structure affects all consumers. The customs clearance system publishes updates, but the tracking service cannot use them directly; it must wait for the data platform team to process them first.</p>
<p>Team A submits a change request. The data platform team determines that the new status value conflicts with a field used by the returns service. They open a discussion with Team B (returns). Team B is mid-cycle on a different priority and cannot engage for two weeks. Meanwhile, the customer portal team begins building a UI for the new status, discovers that the tracking API does not yet expose it, and files a dependency ticket against the data platform.</p>
<p>Weeks pass. Four teams are involved. Seven meetings are held. The two-day change takes six weeks. Nobody considers this unusual.</p>
<p>Microservices were adopted to enable independent deployment inside an organisational structure that could not otherwise move. The promise: split the system into many smaller pieces, each deployed on its own schedule. Teams move faster. Changes stay contained. The organisation stops waiting for a single quarterly release to ship anything at all.</p>
<p>The analogy is a bus. A single bus is faster than walking, slower than a sports car, and hard to reroute. It carries everyone, though, and needs one driver, one maintenance schedule, and one parking space. Replace it with twenty separate cars. Congratulations, you are autonomous: you have your own car. Much more appealing than the bus. Never mind the six tow ropes bolted to the chassis, coupling you to every car around you. No car carries everything it needs to complete a journey alone, because the split was by vehicle type rather than by destination. Every trip still requires multiple cars to coordinate. You now have twenty vehicles to insure, service, and maintain, a logistics problem the bus never had, and a convoy that moves no faster than the slowest car in the chain. You have the maintenance cost of a fleet with the manoeuvrability of a bus. It is what most large organisations built.</p>
<p>Deployment was the visible bottleneck. Ownership was the invisible one. Splitting the code allowed teams to ship without coordinating releases. It did not decompose business processes into owned units. The cars were separated but the convoy remained.</p>
<p>Microservices are not a technology. They are a structural commitment. They only deliver their benefits when each service owns a coherent slice of behaviour and can evolve independently. That independence is not granted by infrastructure or tooling. It is the outcome of a specific design: decomposition around business processes rather than around data entities or technical layers, with ownership, boundaries, and contracts that hold under change. Autonomy without that design is not freedom but chaos that reverts to coordination.</p>
<p>In most of these organisations, that design work was never done, and the consequences are visible in every planning cycle.</p>
<p>Services are defined around database structures, shared infrastructure, or organisational convenience rather than around business processes. One service “owns” a database table. Another “uses” it. A third reconstructs behaviour by reading state through an API. The behaviour itself belongs nowhere. The system is technically decomposed but behaviourally entangled.</p>
<p>The system has the deployment independence of microservices and the coupling of a monolith. The label is precise: a distributed monolith. It has all the operational complexity of a distributed system, hundreds of services to monitor, deploy, and reason about, and none of the benefits that decomposition was supposed to deliver. Changes still require coordination. Failures still cascade. Teams still cannot act independently, because their independence is architectural fiction.</p>
<p>At scale, this entanglement produces a propagation cost that grows faster than the number of connections.</p>
<p>A single source of truth sounds disciplined. In practice, it usually means a single point of coupling. When all teams read from the same database, they are all coupled to its structure, its performance, and its availability. A change to the database structure becomes a global event. A performance issue becomes a shared problem. An outage becomes universal.</p>
<p>The customs vignette illustrates the pattern at small scale. The propagation cost is felt most acutely when external requirements demand change. A regulatory modification to the policy lifecycle, introducing a mandatory cooling-off period, for instance, should be contained within the unit that owns policy activation. In a distributed monolith, “activation” spans five services with dozens of other systems that depend on them. The code change takes days. The dependency negotiation takes months.</p>
<p>The root cause is structural, not technical. The organisation has distributed the system without distributing ownership.</p>
<p>True autonomy requires that a team owns a business process end to end. It requires that the data produced by that process is owned locally and accessed by other teams only through published contracts. It requires tolerating some duplication, because autonomy is more valuable than purity.</p>
<p>Centralised data models optimise for reporting coherence. Distributed data ownership optimises for change velocity. You cannot maximise both at once. These organisations chose coherence for finance. They sacrificed autonomy for engineering.</p>
<p>Granting a team ownership of a real process means accepting that it can make changes without permission, that trade-offs are local, and that failures are visible. That directness is structurally unwelcome in organisations where authority flows from narrative rather than from ownership.</p>
<p>Instead, autonomy is simulated. Teams can deploy independently but not evolve independently, because their data, their dependencies, and their priorities are all controlled elsewhere.</p>
<p>The cost of this simulation is paid in coordination. Every planning cycle includes dependency negotiation. Every significant change requires a cross-team meeting. The meetings are not waste. They are the minimum cost of operating a distributed system without distributed ownership. The organisation could eliminate them by recoupling into a monolith or by granting genuine ownership. It does neither. The coordination tax persists.</p>
<p>For boards, the distributed monolith has three consequences that matter.</p>
<p>Incident cost. When no unit owns the process end to end, incidents cascade across boundaries that were supposed to be independent. The incident bridge call becomes the only place the process is reconstructed. Twenty people join not because the system is complex, but because ownership is. The cost of each incident is higher than it would be in a genuinely autonomous system.</p>
<p>Operational resilience. Regulators increasingly require organisations to demonstrate end-to-end understanding of critical business processes. When those processes span five services with fifty-seven other systems that depend on them, the organisation cannot demonstrate understanding because no single person or team possesses it. The understanding exists socially, distributed across the institutional knowledge of dozens of engineers.</p>
<p>Change velocity. Every strategic change must negotiate the same dependency structure. The two-day change that takes six weeks is not an outlier. It is the baseline. The board approves a strategic initiative expecting delivery in a quarter. The initiative encounters the same dependency negotiation as every other change. Delivery takes three quarters. The board concludes that engineering is slow, but the constraint is not engineering capability. It is the coupling in the structure.</p>
<p>Microservices did not fail because the pattern was wrong. They failed because the organisation adopted the pattern without the design that makes it work: decomposing business processes before decomposing services, defining ownership before distributing execution, establishing contracts before granting independence. Without that design, autonomy cannot exist. The organisation retreats to coordination, and the architecture faithfully reflects the retreat.</p>
</section>
<section id="ch-8">
<h2><a href="./?ch=8">Chapter 8: Data Centralisation and Control Illusions</a></h2>
<p>The renewals team at a Nordic insurer with roughly 3,500 employees and a centralised data platform built over fifteen years needs to track whether customers prefer single-year or multi-year contracts. The field is specific to renewals. No other team uses it. No other team needs it.</p>
<p>Because the customer record is centralised, shared across onboarding, claims, billing, reporting, and compliance, the field cannot be added without a review. The data governance committee meets fortnightly. The committee determines that any change to the customer record requires impact assessment across all teams that read it. Each team must confirm the change does not affect its processes.</p>
<p>The assessments take four weeks. None of the five teams identifies any impact, because the field is irrelevant to all of them. The committee approves the change. The total elapsed time from request to deployment is six weeks.</p>
<p class="continue"><a href="./?ch=8">Continue reading →</a></p>
</section>
<section id="ch-9">
<h2><a href="./?ch=9">Chapter 9: Why Programmes Fail Before They Start</a></h2>
<p>A multinational financial services company headquartered in Western Europe, approximately 25,000 employees across thirty countries, operates as a federation. Local operating entities across those thirty countries, each with their own P\&amp;L, their own priorities, and their own conviction that their market is uniquely special. Central business owners set strategy and policy but have limited direct control over how the local entities operate. A separate, centralised digital and IT function is expected to build platforms for the entire organisation whilst satisfying the contradictory demands of both the centre and the local markets.</p>
<p>The central business owners define the aim. They know what the organisation should become. The digital function executes the build. They are technically competent and the platforms they produce are sound. The local entities, however, own the customer relationship. They control adoption. They decide, in practice, whether anything changes.</p>
<p>The organisation launches a transformation programme. The strategy is clear. The platform is delivered. The local entities do not adopt it. They attend the training, use the new terminology in reporting, and update their dashboards. Nothing changes in how they process transactions, manage client accounts, or serve customers.</p>
<p class="continue"><a href="./?ch=9">Continue reading →</a></p>
</section>
<h2 class="part">Capital Mispricing and Structural Risk</h2>
<section id="ch-10">
<h2><a href="./?ch=10">Chapter 10: Lag Governance and Capital Mispricing</a></h2>
<p>A retail bank with a ten-year-old microservices estate invests € 1.2 million in a shared platform capability: a common communication layer that would let its mortgage, payments, and savings teams exchange information independently, replacing a fragile web of direct connections between systems that causes an average of three incidents per month.</p>
<p>The platform team delivers a working prototype in four months. It is technically sound. The three consuming teams are willing to migrate. The projected incident reduction is 70--80\</p>
<p>The CFO kills the investment in the annual budget review. The platform “does not show ROI in year one.” The cost is visible: € 1.2 million in engineering salaries and infrastructure. The benefit is diffuse: fewer incidents, faster change, reduced coordination overhead. None of these benefits appear as a line item in any business unit’s P\&amp;L.</p>
<p class="continue"><a href="./?ch=10">Continue reading →</a></p>
</section>
<section id="ch-11">
<h2><a href="./?ch=11">Chapter 11: The Coordination Tax and the Alignment Supply Chain</a></h2>
<p>The delivery lead’s calendar shows forty-one hours of meetings this week. She has blocked two hours on Thursday morning for “focus time.” By Tuesday afternoon, a programme steering committee has been scheduled over it.</p>
<p>She does not build anything. She does not decide anything. She translates. She takes what the product manager says the business wants, what the architect says the system can support, and what the engineering teams say they can deliver, and she reconciles them into a plan that satisfies all three. The plan is presented weekly. It is revised weekly. It has never once survived contact with the sprint.</p>
<p>Her role exists because no one in the organisation can talk directly to anyone else. Product cannot talk to engineering because they do not share a vocabulary. Architecture cannot talk to delivery because their artefacts describe different systems. Engineering cannot talk to the business because the business does not attend their meetings. She is the connective tissue.</p>
<p class="continue"><a href="./?ch=11">Continue reading →</a></p>
</section>
<section id="ch-12">
<h2><a href="./?ch=12">Chapter 12: Talent Decay as Structural Fragility</a></h2>
<p>A principal engineer at an ecommerce marketplace with approximately 1,200 employees and a twelve-year-old order management platform raises a concern about a dependency that will block the roadmap. The concern is noted but not addressed. She flags a risk in an architecture review. The risk is acknowledged but deprioritised. She points out that a commitment made to the board cannot be delivered as described. She is told to find a way.</p>
<p>After enough of these exchanges, she stops. Not because she has lost the knowledge. She still sees the problems clearly, still traces the dependencies in her head, still knows which parts of the system are fragile and why. The cost of stating what she sees has become higher than the cost of staying silent. The silence is not apathy. It is the particular exhaustion of someone who has been right, repeatedly, to no effect.</p>
<p>Two years later, she leaves. She takes with her an understanding of the order fulfilment process, the warehouse integration constraints, the payment reconciliation edge cases, and the failure modes of the carrier tracking service that no document in the organisation captures. Her replacement arrives with equivalent credentials and no context. He spends six months learning what she knew on her first day. Some of what she knew, he never learns, because it was never written down.</p>
<p class="continue"><a href="./?ch=12">Continue reading →</a></p>
</section>
<section id="ch-13">
<h2><a href="./?ch=13">Chapter 13: Operational and Regulatory Exposure</a></h2>
<p>A European insurer receives notice of a regulatory change: all policies above € 25,000 annual premium must observe a mandatory 48-hour cooling-off period before activation. During this window, payment may be collected, the policy may be cancelled without penalty, claims are not valid, and risk exposure must not be recognised on the balance sheet.</p>
<p>This is a change to the policy lifecycle, not a feature request.</p>
<p>The insurer has five hundred services in its technology estate. “Activation” is not one system. It spans five: quoting, payments, the policy record, claims eligibility, and broker commissions. Each of these feeds data to dozens of other systems. The policy record alone is consumed by fifty-seven.</p>
<p class="continue"><a href="./?ch=13">Continue reading →</a></p>
</section>
<h2 class="part">Structural Correction</h2>
<section id="ch-14">
<h2><a href="./?ch=14">Chapter 14: Radical Increments</a></h2>
<p>A principal engineer at a Nordic bank inherits a fifteen-year-old payments reconciliation service. She spent two years building a mental model of its behaviour. The service processes € 4 million in daily settlement. Documentation is partial and outdated. She estimates it would take a new hire eighteen months to reach her level of understanding.</p>
<p>Her team runs the codebase through an AI analysis tool. In three days, it produces a structured map of the service’s behaviour: 847 code paths, 23 undocumented failure modes, 6 implicit business rules that exist nowhere in any specification. The map is not complete. It is also more comprehensive than any single person’s understanding. The engineer spends a week annotating and correcting it. She now has an artefact that can be shared, tested, and maintained. The knowledge is no longer in her head alone.</p>
<p>What took two years of accumulated context now takes ten days of structured extraction. That is not an incremental improvement. It is a categorical shift in what is knowable, executed as a bounded, repeatable step.</p>
<p class="continue"><a href="./?ch=14">Continue reading →</a></p>
</section>
<section id="ch-15">
<h2><a href="./?ch=15">Chapter 15: The Unit That Owns the Truth</a></h2>
<p>The payments unit has nine people. Two senior engineers, three engineers, a domain expert named Marta who spent twelve years in payments operations before joining the unit, a data analyst, a reliability engineer, and a unit lead who was previously a senior architect.</p>
<p>They own the payments process: premium collection, claims disbursement, broker commission payments, and refunds. They own the services that implement these flows, the data those services produce, and the contracts through which other units interact with them.</p>
<p>On a Wednesday morning, Marta notices that the refund process has a failure rate that has crept from 0.3\</p>
<p class="continue"><a href="./?ch=15">Continue reading →</a></p>
</section>
<section id="ch-16">
<h2><a href="./?ch=16">Chapter 16: Contracts, Not Committees</a></h2>
<p>The payments unit’s contract requires consuming units to submit payment requests with fully validated customer and account data. This is structurally correct: the payments process should not validate data it does not own.</p>
<p>The consuming units experience this differently. Motor origination finds that validating account data at point of sale adds delay that customers feel. Claims discovers that claimants who have changed banks require a re-verification step that its process definition does not accommodate. Both units face the same incentive: minimise their own validation costs and let the payments unit reject what it cannot process.</p>
<p>The payments unit tightens its contract: stricter formats, more required fields, faster rejection of anything that does not comply. The consuming units add workarounds and automatic retries to handle the rejections. Within six months, the interaction has produced coordination overhead encoded in contracts rather than in meetings, but coordination overhead nonetheless. Payment failures increase. Resolution times lengthen.</p>
<p class="continue"><a href="./?ch=16">Continue reading →</a></p>
</section>
<section id="ch-17">
<h2><a href="./?ch=17">Chapter 17: Data as Outputs, Not a Shared Substrate</a></h2>
<p>In many large corporates, data is treated as a shared resource. A central data team, a common data model, a central repository that collects everything from everywhere and makes it available to everyone. This feels disciplined. It is also the fastest way to destroy the autonomy that the previous chapters described.</p>
<p>The problem is not the aspiration. The aspiration, that the organisation should be able to answer questions that span multiple processes, is legitimate. The problem is the mechanism. When data is shared through a common substrate, every unit that reads from or writes to that substrate is coupled to every other unit that does the same. A change to the data structure in one place propagates to every consumer. A performance issue in one pipeline affects every downstream report. The “single source of truth” becomes a single point of coupling for the organisation’s ability to change.</p>
<p>This chapter makes one argument: data should flow out of autonomous units as a published product, not pool underneath them as a shared substrate. The distinction is structural, not semantic, and it determines whether the organisation can be both autonomous and coherent.</p>
<p class="continue"><a href="./?ch=17">Continue reading →</a></p>
</section>
<section id="ch-18">
<h2><a href="./?ch=18">Chapter 18: Innovation Without Exception Budgets</a></h2>
<p>A European media group with roughly 2,000 employees across publishing, broadcast, and digital divisions launches an innovation initiative around content personalisation. A dedicated team of six, operating outside the normal delivery cadence, builds a machine learning model that recommends articles and video based on reading behaviour and engagement patterns. Governance constraints are relaxed. Architectural standards are temporarily suspended. An external AI consultancy is engaged.</p>
<p>The team delivers in four months. The model works. Users who previously saw a single editorial homepage now receive personalised content streams. Average session duration increases by 18\</p>
<p>Then the initiative ends. The team is reassigned. The model is handed to the editorial technology team, which did not build it, does not understand its training data, and has no process for retraining it when content patterns and audience behaviour shift.</p>
<p class="continue"><a href="./?ch=18">Continue reading →</a></p>
</section>
<section id="ch-19">
<h2><a href="./?ch=19">Chapter 19: What to Demand Before Anything Else</a></h2>
<p>The structural corrections described in this Part are not technology projects. They are redistributions of authority, accountability, and information. Before any role-by-role analysis: the following demands apply now, to the next board pack, without waiting for structural change to complete.</p>
<p>Ask management to bring the following:</p>
<p>1. A process inventory ranked by business criticality. A list of the organisation’s core business processes, ordered by revenue contribution and risk exposure, with a named owner, key performance indicators, and third-party dependencies for each. Where a third party is involved in delivering a business-critical process, whether through outsourced operations, managed services, or embedded vendor systems, the inventory should identify them explicitly. Third-party involvement in a critical process is outsourcing by another name, and it carries concentration risk, contractual exposure, and regulatory obligations that the board must be able to see. Not a capability map. Not a portfolio taxonomy. A list of processes that the organisation actually operates, with a person accountable for each, measures that show how each is performing, and visibility into where the organisation’s delivery depends on parties it does not control. If the list does not exist, or if most processes have no named owner, that is the finding.</p>
<p class="continue"><a href="./?ch=19">Continue reading →</a></p>
</section>
<section id="ch-20">
<h2><a href="./?ch=20">Chapter 20: The Transition and Its Failure Modes</a></h2>
<p>Each executive role is affected differently by the structural corrections described in the preceding chapters. What follows describes, for each, what stops being governable by narrative, what new artefacts become decisive, what to stop rewarding, and what to authorise. First: the structural shift that applies to all of them, and the transition itself.</p>
<p>Most executives reached their position by operating at distance from mechanism: synthesising across functions, weighing trade-offs, allocating capital without holding every operational detail. This distance is how leadership scales. Over time, it becomes identity.</p>
<p>When processes become explicit and contracts become binding, this pattern changes. Machine-readable artefacts shorten the path between commitment and consequence. The executive who is comfortable experiences it as increased control. The executive who is not experiences it as the loss of interpretive insulation: the capacity to reframe outcomes, diffuse responsibility, and manage contradiction through narrative rather than mechanism. Boards are not always the victims of this resistance. In some organisations, the board is a co-participant: preferring the smoothed narrative because interrogating it would require confronting structural problems the board itself has tolerated.</p>
<p class="continue"><a href="./?ch=20">Continue reading →</a></p>
</section>
<section id="ch-21">
<h2><a href="./?ch=21">Chapter 21: What the Sceptical Board Member Asks</a></h2>
<p>The arguments in this book will face predictable objections. Addressing them directly is more useful than pretending they do not exist.</p>
<p>“The AI technology is not mature enough.”</p>
<p>This objection conflates the technology with the artefacts. The technology required for the core synthesis, comparing process definitions against code, detecting contract violations, producing reconciliation reports, is available today as commodity capability. Current large language models can read structured process definitions alongside code and identify where implementation diverges from intent. Checking whether contracts are being honoured is straightforward software, not AI.</p>
<p class="continue"><a href="./?ch=21">Continue reading →</a></p>
</section>
<section id="ch-22">
<h2><a href="./?ch=22">Conclusion</a></h2>
<p>\addtocontentstoc\protect\addvspace0.5em</p>
<p>This book has described a structural problem and a structural solution. The problem is that most large organisations cannot describe themselves clearly enough for AI to produce anything other than faster narrative. The solution is to make the organisation legible: explicit processes, owned boundaries, versioned contracts, and structured artefacts that can be tested against the systems that run the business.</p>
<p>Chapter 2 described the fork: AI as a writer of narrative, or AI as a reader of systems. The two are contradictory. An organisation that uses AI to generate a board pack claiming a migration is 70\</p>
<p>The choice between these paths is a governance decision, not a technology decision, because AI can only read what the organisation has made legible. Without the structural changes described in Part IV, AI reads whatever the organisation gives it. The organisation will conclude that synthesis “does not work yet” and retreat to the writing path. The retreat is not a technology failure. It is a structural one.</p>
<p>The two paths diverge, and the divergence compounds. An organisation that begins making itself legible now builds structural capability with independent returns. An organisation that defers accumulates the opposite: unverified claims at machine speed, a widening deficit against competitors already compounding coherence.</p>
<p>Chapter 3 acknowledged that in regulated industries with high switching costs, the suppression equilibrium can persist for decades. What changes the calculus is visibility. Once the board has seen a reconciled synthesis, the position shifts from ignorance to informed inaction. The former is defensible. The latter is a governance risk that compounds with every board cycle in which the findings are noted and not acted on.</p>
<p>The deferral is not neutral. An organisation that adopts AI as a narrative tool, generating board packs, polishing status reports, producing strategy updates, builds institutional dependence on the output. Roles form around producing and approving it. The board adjusts to receiving it. Switching to the reader path then requires not merely deploying a different capability but withdrawing confidence from the narrative the organisation has spent years constructing. The political cost of that switch rises with every governance cycle in which the writer becomes further embedded, and deferral forecloses the option it appears to preserve.</p>
<p>The forces described in Part III reinforce this narrowing. Regulatory frameworks already require traceable process evidence that narrative governance cannot produce cheaply. Deferred platform investments accumulate incident costs that reconciliation can now connect to their structural cause. The experienced engineers who could make processes explicit are leaving, and each departure destroys context that was never captured in any artefact. These pressures do not arrive as a single crisis. They arrive as a narrowing window in which the cost of the structural work rises while the organisational capacity to do it declines.</p>
<p>The structural changes described in this book cannot be delegated to a transformation programme, a technology team, or an external consultancy.</p>
<p>They cannot be delegated to a transformation programme, because transformation programmes are approved by the same executives whose authority the change redistributes. They cannot be delegated to the technology team, because the change is organisational, not technical. They cannot be delegated to a consultancy, because consultancies must produce recommendations acceptable to the executives who commissioned the engagement.</p>
<p>The choice must be made by the people with authority to redistribute power within the organisation. This means the CEO and the board. The closing chapters describe what each must demand and sustain.</p>
<p>If an AI system attempts to synthesise an organisation from its artefacts, strategy documents, process definitions, architecture models, and code, will that synthesis converge on something coherent, or collapse into contradiction?</p>
<p>The answer depends on whether those artefacts exist as machine-readable, owned descriptions or as implicit knowledge carried in people’s heads. That is the test for any board. It does not require a programme, a consultancy, or new technology. It requires one question: can this organisation describe itself clearly enough for a machine to read it?</p>
<p>The question can be made specific. Take one critical business process: claims adjudication, mortgage origination, payment settlement, whatever process generates the most revenue or carries the most risk. Ask: does a machine-readable description of this process exist? Can it be reconciled against the code that implements it? Can the reconciliation identify contradictions without human interpretation? If the answer to any of these is no, the organisation has identified the first unit of structural work, and every AI investment it makes until that work is done will produce faster narrative rather than structural improvement.</p>
<p>If the answer is yes, or if the organisation is willing to do the structural work to make the answer yes, AI becomes a continuous reconciliation engine. The two paths compress to their essentials. Suppression accelerates narrative velocity while structural fragility compounds and regulatory exposure accumulates. Reconciliation produces short-term discomfort and political friction, but builds compounding capability.</p>
<p>A board member opens a reconciliation report at 7:40 on a Tuesday morning, twenty minutes before the quarterly review. The report is six pages. It compares the renewals process definition against the code that implements it. She reads that the automated risk reassessment described in the strategy update has not been implemented. The renewals process still routes every modified policy to a manual review queue. The queue is staffed by four people. Average time in queue: eleven days. The strategy update she approved last quarter described the reassessment as “deployed and in optimisation.” She turns to the management narrative prepared for this morning’s meeting. Page three describes renewals performance as “on track, with automated reassessment reducing processing time by 40\</p>
<p>She sets the management narrative down. She does not speak, she does not need to.</p>
<p>Once reconciliation is technically possible, the absence of reconciliation becomes evidence. A board that has never seen a reconciled synthesis operates in ignorance. A board that has seen one and chosen not to act operates in preference.</p>
<p>That preference is discoverable. Reconciliation outputs are records. In any subsequent regulatory inquiry, acquisition due diligence, or internal audit, the question is no longer whether the organisation could have verified its own representations. The capability exists. It is available at negligible cost. The question becomes why it was not used, and the board’s answer is now part of the governance record.</p>
<p>The capacity for structural honesty now exists, and it does not require new technology, a transformation programme, or external validation. It requires a decision by the people with authority over the organisation’s structure. The writer path deepens with every governance cycle. The people who carry the context to make processes explicit are leaving, and each departure destroys knowledge that was never captured in any artefact. Each quarter of informed inaction extends a record the board will eventually be asked to explain. The structural preconditions described in this book take years to build and cannot be purchased when the need becomes urgent. I have worked inside organisations on both sides of this choice, and the difference compounds faster than any board expects. What remains, after the argument is made and the evidence is assembled, is whether the people who govern these organisations are willing to see what is already there, and to act on it before the people who could have helped them are gone.</p>
</section>
<section id="ch-23">
<h2><a href="./?ch=23">About the Author</a></h2>
<p>Adrian McPhee has spent more than twenty years as an engineer, architect, and CTO inside software-dependent corporates across fintech, retail, and mobility, including a unicorn fintech, a leading ecommerce marketplace, and a multinational with €10 billion turnover. He has led organisations of up to a thousand people, delivered global platforms, and redirected more than €200M of product and technology investment. He watched the same structural dysfunctions repeat across every organisation he entered, and eventually learned to dismantle them.</p>
<p>As a founder and entrepreneur, he also designs and delivers platforms from scratch. It is the same discipline this book argues for: explicit structure, reconciled with reality, that a machine can actually read.</p>
<p>He now works with leadership teams to diagnose and dismantle the patterns described in this book. The operational perspective on these patterns, how processes become implicit, how architecture becomes avoidant, and what changes when they are made explicit, is examined in Illusions of Work, which is written for the CTO and engineering leadership audience that must execute the structural changes this book authorises.</p>
<p class="continue"><a href="./?ch=23">Continue reading →</a></p>
</section>

  <div class="cta">
    <p>Read the full book in the interactive reader</p>
    <a href="./">Start reading</a>
  </div>

  <footer>
    <p>&copy; Adrian McPhee 2026 &middot;
    <a href="https://www.linkedin.com/in/adrianmcphee/" style="color: #999;">Contact</a></p>
  </footer>
</body>
</html>