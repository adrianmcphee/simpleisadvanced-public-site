<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Illusions in the Boardroom by Adrian McPhee — Preview</title>
  <meta name="description" content="Synthesis is now cheap. Pretence is not. Read the opening chapters of AI Illusions in the Boardroom by Adrian McPhee.">
  <meta name="author" content="Adrian McPhee">
  <meta property="og:type" content="book">
  <meta property="og:title" content="AI Illusions in the Boardroom by Adrian McPhee">
  <meta property="og:description" content="Synthesis is now cheap. Pretence is not. Read the opening chapters free.">
  <meta property="og:image" content="https://simpleisadvanced.com/ai-illusions-in-the-boardroom/og-image.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <link rel="canonical" href="https://simpleisadvanced.com/ai-illusions-in-the-boardroom/">
  <style>
    body { max-width: 42em; margin: 2em auto; padding: 0 1.5em; font-family: Georgia, serif;
           line-height: 1.7; color: #222; background: #fff; }
    h1 { font-family: system-ui, sans-serif; font-size: 1.8em; margin-bottom: 0.2em; }
    h1 + p { color: #666; font-style: italic; margin-top: 0; }
    h2 { font-family: system-ui, sans-serif; font-size: 1.3em; margin-top: 2.5em;
          border-top: 1px solid #e5e5e5; padding-top: 1.5em; }
    h2.part { font-size: 0.85em; text-transform: uppercase; letter-spacing: 0.1em;
              color: #999; border: none; margin-bottom: -1em; padding-top: 2em; }
    h2 a { color: inherit; text-decoration: none; }
    h2 a:hover { color: #c0392b; }
    h3 { font-family: system-ui, sans-serif; font-size: 1.05em; margin-top: 1.5em; }
    p { margin: 0.8em 0; }
    .continue { font-family: system-ui, sans-serif; font-size: 0.9em; }
    .continue a { color: #c0392b; text-decoration: none; }
    .continue a:hover { text-decoration: underline; }
    .header { text-align: center; margin-bottom: 3em; }
    .header img { max-width: 200px; margin-bottom: 1em; }
    .cta { text-align: center; margin: 3em 0; padding: 2em; background: #f9f9f9;
            border-radius: 8px; font-family: system-ui, sans-serif; }
    .cta a { display: inline-block; padding: 0.7em 2em; background: #222; color: #fff;
             text-decoration: none; border-radius: 4px; font-weight: 600; }
    .cta a:hover { background: #444; }
    .banner { position: sticky; top: 0; z-index: 100; background: #222; text-align: center;
               padding: 0.75em 1em; font-family: system-ui, sans-serif; font-size: 0.9em;
               margin: -2em -1.5em 2em; }
    .banner a { color: #fff; text-decoration: none; font-weight: 500; }
    .banner a:hover { text-decoration: underline; }
    footer { text-align: center; color: #999; font-size: 0.85em; margin-top: 3em;
             padding-top: 1.5em; border-top: 1px solid #e5e5e5; }
  </style>
</head>
<body>
  <div class="banner">
    <a href="./">Read in the interactive reader &rarr;</a>
  </div>

  <div class="header">
    <img src="cover.png" alt="AI Illusions in the Boardroom">
    <h1>AI Illusions in the Boardroom</h1>
    <p>Synthesis is now cheap. Pretence is not.</p>
    <p style="font-style: normal; font-size: 0.9em;">Adrian McPhee</p>
  </div>

<section id="ch-0">
<h2><a href="./?ch=0">Author's Note</a></h2>
<p>I have spent more than twenty years inside software-dependent corporates in roles ranging from engineer to CTO. I served as CTO of a leading ecommerce marketplace with more than 13 million customers, led a technology organisation of over a thousand people as CTO of an ECB-regulated multinational with €10 billion turnover, and transformed how hundreds of engineers work at a unicorn fintech. I have redirected hundreds of millions in product and technology investment and written off programmes that should never have been funded.</p>
<p>Throughout those years, I watched talented people lose to structures that rewarded ambiguity over precision. Engineers who understood the real system were told they lacked soft skills. Architects who presented honest assessments were told they needed to be more strategic. The people who could describe what was actually happening were systematically sidelined in favour of those who could describe what the organisation wanted to hear. The dysfunction was visible to everyone who worked close to reality. It was simply too expensive to confront.</p>
<p>For the past few years I have been using AI daily: building a sophisticated platform from scratch for Eccasion (eccasion.com) with serial founders of a European mobility company, leading a large-scale SDLC overhaul to make a unicorn AI-ready, and developing TuinPlan (demandops.com), an AI-native digital twin for garden planning. What I noticed across all of this work was that the real value of AI was not generation. It was synthesis: reconciling what people said they would build with what was actually there. I kept business plans, user journeys, and process descriptions in structured, machine-readable formats. I could point an AI at those artefacts alongside the codebase and ask where intent and reality had diverged. The AI could answer because the inputs were explicit enough to parse. Vagueness did not produce flexibility. It produced hallucination.</p>
<p>That discovery connected something. The dysfunction I had watched for twenty years is now colliding with a technology that inverts its economics entirely. The gap between narrative and reality, the exhaustion of the people who bridged it, the structures that made vagueness cheap and clarity expensive: all of it is meeting a technology that makes those conditions untenable, and faster than the people inside these organisations have grasped. The economy of vagueness is collapsing. AI does not operate on narrative, seniority, or organisational ritual. It operates on explicit, parseable descriptions of how things actually work. The conditions that make AI effective are exactly the conditions those same people have been asking for all along: explicit processes, real ownership, a straight line from business language into the code. And those people, the ones closest to reality, the ones the organisation has been exhausting since the early 2010s, are precisely the ones it now needs most.</p>
<p>When I described this pattern publicly, the recognition was immediate and far broader than I expected.</p>
<p>So I wrote the book. It is blunt, sometimes uncomfortably so. That is not a stylistic choice. It is a structural one. A book arguing that AI forces reconciliation between what you say and what is actually true cannot hedge, soften, or add diplomatic padding without becoming the thing it describes. The pathology is specific: organisations where software mediates value creation but governance has not adapted. Where ambiguity reflects genuine domain uncertainty rather than structural avoidance, the diagnosis does not apply.</p>
</section>
<section id="ch-1">
<h2><a href="./?ch=1">Introduction</a></h2>
<p>Most executives no longer need convincing that artificial intelligence can generate content. The generative capability is embedded in workflow: drafting strategy documents, summarising board packs, analysing contracts, exploring financial models, generating production code. This book is not about that capability.</p>
<p>It is about a different one: AI’s ability to reconcile.</p>
<p>When a machine can read what you say alongside what your systems do, the gap between narrative and reality becomes measurable. A strategy document can be compared against the codebase that must implement it. An architecture reference model can be compared against the deployment topology that actually exists. A budget line can be compared against the operational outcomes it was meant to produce. A portfolio label can be compared against the services that supposedly comprise it. An investment case can be compared against the incident costs it was meant to prevent.</p>
<p>These comparisons are not hypothetical. They are available today, at negligible cost, to any organisation willing to point an AI system at its own artefacts and ask a simple question: does what we say match what we do?</p>
<p>For most organisations, the answer is no. Not because the people inside them are dishonest, but because the structures they operate within have made honesty expensive and vagueness cheap for more than a decade.</p>
<p>This book uses a specific term: software-dependent corporate. It refers to large, established organisations whose products and operations depend critically on software, but whose governance structures were designed for a world in which software was a support function.</p>
<p>Banks, insurers, retailers, logistics firms, airlines, public sector bodies, and older companies that describe themselves as technology companies but still operate with inherited governance assumptions all fall into this category. These organisations are not pre-software. They have had software for decades. What they have not adapted to is the shift that occurred between roughly 2008 and 2012, when software stopped being infrastructure and became the primary medium through which these companies create and deliver value.</p>
<p>By 2012, the structural change was complete: these organisations needed to become software companies. They hired engineers by the hundreds, adopted continuous delivery, and launched digital transformation programmes. But the governance structures, the budget cycles, the HR frameworks, and the executive mental models stayed where they were. The technology changed. The power structures did not. The misalignment has been compounding ever since.</p>
<p>The most reliable diagnostic is linguistic. If your organisation talks about “the business” as a group of people who are not engineers, your organisation is a software-dependent corporate. If engineers are considered to work in the business by default, it probably is not.</p>
<p>Once that split exists, reality becomes optional.</p>
<p>Software-dependent corporates evolved structures that separate “the business” from engineering, producing what this book calls illusions of work: narratives that replace reality, portfolio labels with no executable boundary, avoidant architecture, processes that were never written down. These illusions are not stupidity. They are coping mechanisms. They are how intelligent people remain functional inside structures that will not let them do real work.</p>
<p>Since that shift, these organisations have survived the misalignment by making reality expensive and vagueness cheap. Understanding the system required meetings. Reconciling strategy required interpretation. Connecting cost to value required politics. The dysfunction was real, but it was survivable. Human synthesis could bridge the gap, expensively, and market position provided insulation.</p>
<p>For two decades, organisations absorbed the reconciliation cost socially: through meetings, translation roles, governance ritual, and institutional memory. A small number of people in each organisation carried the real system in their heads. They knew which architecture diagrams were fiction. They knew which products did not exist as coherent systems. They knew which processes had never been written down. They performed the synthesis that kept the organisation from flying apart. It was inefficient, fragile, and entirely dependent on the continued presence and goodwill of those people. But it held.</p>
<p>AI destabilises that equilibrium.</p>
<p>Synthesis is the act of reading multiple artefacts together and producing a coherent understanding of their relationships. In organisational terms, it means answering questions like: Does our architecture support our strategy? Does our system behave according to our process definitions? Are our teams organised around the processes they are meant to own? Do our costs align with the value we are creating?</p>
<p>Before AI, answering these questions required a human who had access to all the relevant artefacts, understood each of them, and could hold them in mind simultaneously. In a large organisation, no single person has access to the strategy deck, the codebase, the process definitions, the cost data, and the customer feedback simultaneously. Different people hold different pieces. Synthesis required gathering these people in a room, which required scheduling, which required authority, which required political capital.</p>
<p>Even when the right people were gathered, synthesis was slow. A comprehensive reconciliation of strategy, architecture, process, and outcomes might take a consulting engagement of twelve weeks. By the time it was complete, the system had changed.</p>
<p>AI collapses this cost. It reads everything it is given in parallel. It does not tire. It does not defer to seniority. It produces a synthesis in hours rather than weeks. The synthesis is not perfect; it reflects the quality of the inputs. But it is fast, cheap, and reproducible. It can be run weekly rather than annually. It can be updated as artefacts change rather than becoming stale the moment it is produced.</p>
<p>When synthesis costs twelve weeks of consulting time, you do it once a year at most. When it costs hours of compute time, you do it continuously. When you do it continuously, the gap between narrative and reality cannot grow large, because it is detected and surfaced before it accumulates.</p>
<p>There is a simple test for any software-dependent corporate. If an AI system reads your strategy documents, your architecture models, your process descriptions, and your codebase together, will the synthesis converge on something coherent? Or will it collapse into contradiction?</p>
<p>The answer depends on whether the organisation’s representations of itself, its strategy, its structure, its processes, exist as explicit, machine-readable descriptions that can be parsed and reasoned about without human interpretation, or whether they exist as implicit knowledge carried in people’s heads and negotiated in meetings.</p>
<p>Consider what reconciliation looks like in practice.</p>
<p>Strategy claim versus code reality. Your strategy commits to API-first design. The AI reads the codebase and finds that 62\</p>
<p>Architecture model versus deployment topology. Your architecture reference model describes eight bounded contexts with clear data ownership. The actual service topology follows a different structure: one organised around legacy database schemas rather than business domains. Fourteen services share a single relational database. The reference model describes nothing real.</p>
<p>Investment case versus incident cost. The CFO rejected a platform resilience investment three years running because the ROI case was unclear. The AI reads the incident log and calculates that the incidents caused by the missing investment have cost € 2.1 million in the same period. The CFO’s numbers were accurate. They were also incomplete. The incompleteness is now visible.</p>
<p>Portfolio label versus executable boundary. A product called “Customer Engagement” has a P\&amp;L, a headcount allocation, and a roadmap. An enterprise architect asks which services comprise it. After a forty-five-minute sidebar, no one in the room can draw a coherent boundary around it. The product exists in the portfolio. It does not exist in the system.</p>
<p>Each of these gaps has been survivable, individually, for years. The people closest to the system knew they existed and worked around them. What changes is the cost of knowing. Reconciliation that once required months of expert human attention is now available continuously, cheaply, and without political filtering.</p>
<p>Synthesis is now cheap. Pretence is not.</p>
<p>This book explains what changes when machines can reconcile strategy documents, architecture artefacts, budget lines, portfolio labels, data governance claims, and innovation initiatives against production reality. It names why the previous equilibrium was survivable, why it is destabilised by cheap synthesis, and what structural changes allow an organisation to benefit rather than merely accelerate its own illusions.</p>
<p>Part I, The Illusion Was Rational, shows how software-dependent corporates produce and stabilise representations that cannot be reconciled with the systems they describe. The illusions are not failures of intelligence. They are coping mechanisms with a cost structure.</p>
<p>Part II, When Machines Read, introduces the inversion. AI makes reconciliation cheap and continuous. The generator capability is real but incremental. The reader capability is structural. What changes is not what AI can produce, but what it can reveal.</p>
<p>Part III, Capital Mispricing and Structural Risk, traces the consequences. When the gap between narrative and reality becomes measurable, capital allocation, coordination costs, talent retention, and regulatory exposure are all repriced. The costs were always real. They are now visible.</p>
<p>Part IV, Structural Correction, describes what changes when the structure stops working against the people inside it. Not frameworks. Not principles. The specific structural commitments that make an organisation machine-readable: process ownership, contracts, data governance, and the executive decisions that authorise them.</p>
<p>The conclusion presents the choice. You can accelerate narrative production, using AI to generate more confident representations faster. Or you can reconcile reality continuously, using AI to surface contradictions between what you say and what your systems do. These two paths are incompatible without structural change. The choice cannot be delegated.</p>
</section>
<h2 class="part">The Illusion Was Rational</h2>
<section id="ch-2">
<h2><a href="./?ch=2">Chapter 1: The Board Narrative and the System</a></h2>
<p>The CEO of a mid-sized European insurer is eighteen months into her tenure. She has done what a competent CEO should do. She hired a respected CTO from a digital-native company. She funded a three-year technology modernisation programme at € 40 million, more than the board wanted, less than the CTO asked for, a reasonable compromise. She approved a new organisational structure: product-aligned teams, a platform group, an architecture function. She attended the first two quarterly reviews personally, to signal commitment.</p>
<p>The strategy is coherent. The CTO is capable. The funding is real. The board is supportive.</p>
<p>Two years in, the core measures she cares about have not moved: time to market for new products, operational cost per policy, customer retention. Two major initiatives have been quietly descoped. The CTO reports progress. The CFO reports cost. Neither report contradicts the other. Neither explains why the organisation feels no different.</p>
<p>She asks her direct reports. Each gives a plausible account. The CTO says the legacy systems are harder to untangle than expected. The CFO says the technology spend is growing faster than the revenue it was meant to unlock. The COO says the teams are still learning to work in the new model. None of them is lying. None of them is wrong. And none of them is describing the same organisation.</p>
<p>She commissions an external review. The consultants produce 120 slides. The diagnosis is familiar: alignment gaps, unclear ownership, siloed delivery. The recommendation is another reorganisation, a new operating model, a governance framework. She has seen this pattern before, at her previous company. She approved the same kind of review there. It produced the same kind of recommendations. She left before the results were visible. This time she stays. The results will not be visible this time either.</p>
<p>She suspects the problem is not alignment, or talent, or even legacy technology. She suspects it is something in the structure itself, something that makes every reasonable decision produce unreasonable outcomes. But she cannot name it, because nothing in her reporting, her reviews, or her advisory relationships is designed to make it visible.</p>
<p>She approves the consultants’ recommendations. There is nothing else to approve.</p>
<p>This is a failure of legibility. No business process in the organisation is defined explicitly enough to connect the strategy to the systems that must enact it. Each report is locally rational. None can be reconciled with the others, because no shared description of how the organisation actually works exists to reconcile them against.</p>
<p>The CEO is not incompetent. She is governing through representations that cannot be reconciled. This was the rational outcome of a governance model designed before software became the medium through which the organisation creates value. The representations she receives were not designed to be reconciled against the system. They were designed to be approved. Naming this is not an accusation. It is a structural observation, and the first step towards changing the economics that produced it.</p>
<p>Every board of a software-dependent corporate receives a narrative. It arrives as a board pack, a set of management reports, a quarterly business review. It contains financial performance, programme status, risk registers, and strategic progress. Each section is produced by a different function. Each section is internally consistent. Each section describes the organisation from its own perspective.</p>
<p>The board reads these sections as a composite picture of the organisation. They are not. They are parallel descriptions of different organisations, each using its own language, its own measures, and its own definition of success.</p>
<p>The CFO’s section reports financial performance against budget. It measures cost, revenue, and margin. It tracks capital expenditure on technology programmes. It is accurate, detailed, and complete within its own frame. What it does not do is connect expenditure to system behaviour. A € 40 million technology programme appears as a cost line. Whether the programme has changed anything in the system that creates value is not measured, because the financial model was not designed to connect cost to system capability.</p>
<p>The CTO’s section reports technology progress. Deployment frequency is up. A new customer-facing application has launched. The recruitment brand is stronger. These are real achievements. What the section does not do is connect them to the board’s strategic priorities. “Deployment frequency” measures engineering activity. It does not measure whether the organisation can bring a new product to market faster. The new application launched, but the processes it supports still span six services maintained by three different teams. The application is a surface. The structure underneath it has not changed.</p>
<p>The COO’s section reports operational performance. Claims processing times, customer satisfaction scores, incident frequency. Each metric is defined, tracked, and reported with rigour. What the section does not do is explain whether operational performance is constrained by the system or by the people running it. A claims processing time of 14 days may reflect a complex process or a system that routes claims through five services that share no common data model. The metric does not distinguish between the two. The board cannot tell.</p>
<p>Each section is locally consistent. Taken together, they are globally incoherent.</p>
<p>This incoherence is not new. What is new is naming the mechanism that produces it.</p>
<p>Software-dependent corporates govern through representations: strategy documents, operating models, architecture diagrams, portfolio views, KPI dashboards, board packs. These representations serve a legitimate purpose. No CEO or board member can understand every system in a large organisation. Representations provide the abstraction necessary for governance at scale.</p>
<p>The problem arises when representations replace the thing they represent.</p>
<p>A KPI that measures deployment frequency is a representation of engineering activity. If the board treats it as a measure of technology capability, it has confused the representation with the thing it was meant to represent. Deployment frequency tells you how often code is released. It tells you nothing about whether the code released changes anything that matters to the organisation’s strategy.</p>
<p>A portfolio view that shows “Customer Engagement” as a product with a P\&amp;L and a roadmap is a representation of a business capability. If the portfolio treats it as something that can be funded, measured, and held accountable, it has confused the label with the system. In many organisations, the product called “Customer Engagement” has no coherent boundary in the codebase. It is a name applied to a collection of features scattered across services maintained by different teams. The portfolio label exists. The product does not.</p>
<p>An operating model that describes end-to-end processes in clean swimlane diagrams is a representation of how work flows through the organisation. If the board treats it as a description of how the organisation actually works, it has confused aspiration with reality. In most software-dependent corporates, the operating model describes how the organisation wishes it worked. The system describes how it actually works. The gap between the two is where the cost lives.</p>
<p>This pattern has a specific structure. The representation is produced by someone who understands one part of the system. It is reviewed by someone who understands a different part. It is approved by someone who understands neither but needs a basis for decision. At each stage, the representation becomes more polished and less connected to reality. By the time it reaches the board, it is locally consistent, professionally formatted, and describes an organisation that does not exist.</p>
<p>How does this incoherence survive? Why does the board not notice?</p>
<p>The answer is absorption. The gap between the board narrative and the system is bridged socially, by people whose job is to translate between the two. These translation roles are so pervasive in software-dependent corporates that they are invisible. Programme managers, delivery leads, portfolio analysts, strategy consultants, business partners, integration managers: each of these roles exists to reconcile representations that cannot be reconciled structurally.</p>
<p>These people are not performing unnecessary work. They are performing essential work. Without them, the gap between narrative and reality would produce immediate, visible failure. Board decisions would collide with system constraints. Strategy would contradict architecture. Budget allocation would conflict with operational need.</p>
<p>Translation roles absorb the contradiction. They attend the meetings where different parts of the organisation describe different realities. They interpret, negotiate, and smooth. They produce the synthesis that allows the board to believe it is governing a coherent organisation. This synthesis is expensive, fragile, and entirely dependent on the continued presence and institutional knowledge of the people performing it.</p>
<p>The absorption mechanism creates a specific failure mode. Because the translation is social rather than structural, it cannot be audited, versioned, or transferred. When a programme manager who has spent three years bridging between the CTO’s technology architecture and the CFO’s cost model leaves the organisation, that bridge collapses. The knowledge was never written down in a form that someone else could use. It existed in the person’s head, in the relationships they had built, in the mental model they had constructed by attending hundreds of meetings.</p>
<p>The organisation responds by hiring a replacement and waiting six to twelve months for the new person to reconstruct the bridge. During this period, the gap between narrative and system widens, decisions are made with less accurate information, and costs accumulate invisibly.</p>
<p>Boards were designed to govern through representations. Financial reports, management accounts, risk registers, and strategic plans are all representations. This is appropriate and necessary. A board cannot and should not understand every service, every data flow, every process exception in a large software-dependent corporate.</p>
<p>The question is what happens when the representations cannot be reconciled against the system they describe.</p>
<p>When the representations are accurate, governance through representations works. The financial report reflects real costs connected to real activities. The strategic plan describes real capabilities connected to real systems. The risk register reflects real exposures connected to real failure modes. The board can govern effectively because the abstraction is faithful.</p>
<p>When the representations are disconnected from reality, governance through representations produces decisions that are locally rational and globally incoherent. The board approves a € 40 million programme because the business case is compelling, not knowing that the system cannot deliver on the business case without structural changes that the programme does not include. The board measures technology progress by deployment frequency, not knowing that the deployments are not connected to the strategic priorities. The board accepts an operating model that describes a process no one has verified against the system.</p>
<p>The constraint is not that boards are incompetent. The constraint is that the artefacts they receive are not designed to be reconciled against reality. They are designed to be approved.</p>
<p>A board pack that presents financial performance, technology progress, and operational metrics as three separate sections is not a synthesis. It is three parallel descriptions. The synthesis, the understanding of how these three dimensions interact, either happens in the room, performed by executives who carry the mental model, or it does not happen at all.</p>
<p>When AI makes reconciliation cheap, this constraint changes. The board does not need to understand every service. It needs artefacts that have been reconciled against the system before they arrive, so that the contradictions are surfaced, not smoothed. The question is whether the organisation is willing to produce those artefacts. That willingness requires structural change, which is the subject of the rest of this book.</p>
</section>
<section id="ch-3">
<h2><a href="./?ch=3">Chapter 2: Portfolio Labels That Do Not Exist in Code</a></h2>
<p>The product review is held monthly. Each product owner presents to the CPO and a panel of senior stakeholders. Richard, the product owner for “Customer Engagement,” presents third. His slides show a funnel, a set of KPIs, and a roadmap with six items colour-coded by quarter. The presentation is fluent, the narrative confident. Customer Engagement is growing. Retention is improving. The team has delivered twelve features this quarter.</p>
<p>Then an enterprise architect named Peter asks a question. “Which services comprise Customer Engagement?”</p>
<p>The room shifts. Richard begins to answer, then pauses. Customer Engagement, it turns out, is not a system. It is a label applied to a collection of features that span four different services, maintained by three different teams, two of which report into a different product area. The notification service is shared with Operations. The recommendation engine sits inside a legacy monolith nominally owned by Transactions. The analytics pipeline runs on infrastructure maintained by a platform team that was recently reorganised.</p>
<p>The question requires a forty-five-minute sidebar. By the end of it, no one in the room, including Richard, can draw a coherent boundary around the thing called Customer Engagement. It has a P\&amp;L. It has a headcount allocation. It has a roadmap. It does not have a boundary that corresponds to anything in the system.</p>
<p>The review continues. Nobody suggests that the product definition might be the problem. The action item is for Richard to “work with architecture to clarify the technical landscape.” It will be deprioritised within two weeks.</p>
<p>Customer Engagement continues to exist as a product. Peter’s question is not raised again.</p>
<p>Peter’s question is the diagnostic. Every software-dependent corporate has a version of it: a portfolio label that has a P\&amp;L, a headcount, and a roadmap, but no coherent boundary in the codebase.</p>
<p>This chapter names the pattern and explains why it matters to boards.</p>
<p>A fake product is a P\&amp;L label with no executable boundary. It has all the governance artefacts of a real product: ownership, funding, a roadmap, quarterly reviews, KPIs. What it does not have is a boundary that corresponds to anything in the system that creates and delivers value.</p>
<p>The product exists in the portfolio. It does not exist in code.</p>
<p>This is not a documentation failure. It is a structural one. The product was defined by market narrative, organisational convenience, or portfolio taxonomy rather than by coherent behaviour. It was created because a strategy deck identified a growth area, because a reorganisation needed to assign headcount, or because a competitor had something with a similar name. Ownership was assigned before boundaries were understood. Execution was expected to follow.</p>
<p>When reality refused to conform, when it became apparent that the product spanned multiple systems, multiple teams, and multiple processes with no clear ownership of any of them, the organisation did not revisit the definition. That would have required admitting that the strategic narrative was disconnected from the system. Instead, it inserted a translation layer: a product owner tasked with making the incoherent appear coherent.</p>
<p>Boards and executives can identify fake products without looking at code. The symptoms are visible in governance artefacts.</p>
<p>The boundary question fails. When someone asks “which services comprise this product?” and the answer requires a forty-five-minute sidebar, the product does not have a boundary. Peter’s question was not a technical question. It was a governance question. It asked whether the thing being funded and measured had any correspondence to the thing being built and operated. The answer was no.</p>
<p>Features are delivered but outcomes do not move. Twelve features delivered. Retention improving. But the customer experience has not changed, because the features are scattered across systems that do not share a coherent process. Each feature works in isolation. Together, they do not compose into anything the customer experiences as a product.</p>
<p>Dependencies are permanent. The product cannot make changes without coordinating with teams that report into different product areas. Every change requires negotiation. Every release requires synchronisation. The product has ownership on paper but not in practice.</p>
<p>The P\&amp;L is synthetic. Revenue and cost are allocated to the product by accounting convention rather than traced through systems that the product owns. The financial model looks precise. The precision is artefactual: it reflects the allocation method, not the value creation mechanism.</p>
<p>Incident responsibility is diffuse. When the product breaks, the incident bridge call requires people from three or four teams, because no single team owns the end-to-end process. The product owner is “accountable” but has no authority over the systems involved. Accountability without agency is performance, not governance.</p>
<p>Fake products persist because they serve a governance need. They give the board something to fund, measure, and hold accountable. They fit into portfolio frameworks. They provide a unit of analysis for capital allocation. They make the organisation legible at the level that boards and investors require.</p>
<p>Dissolving the fake product would require admitting that the unit of value creation is not the portfolio label but the business process underneath it. That admission has consequences. It means the product structure does not match the system structure. It means that capital has been allocated to labels rather than to capabilities. It means that the governance framework is measuring representations rather than behaviour.</p>
<p>These admissions are uncomfortable for everyone involved. The product owner’s role depends on the product being real. The CPO’s portfolio depends on the products being coherent. The board’s oversight depends on the portfolio being meaningful. Dissolving the fake product pulls on all of these threads simultaneously.</p>
<p>So the product persists. Peter’s question is not raised again. And the organisation continues to fund, measure, and govern something that does not exist in the system.</p>
<p>When the gap between the portfolio label and the system is permanent, the organisation fills it with a buffering function. Product management, as practised in many software-dependent corporates, becomes that buffer.</p>
<p>This is not a criticism of product managers. Many are skilled, committed, and deeply frustrated by the conditions in which they work. The problem is the role as it has been shaped by the organisational structure: positioned as the interface between the business and engineering, tasked with owning value that spans systems nobody owns, maintaining alignment between narratives that cannot be reconciled with systems that cannot be easily changed.</p>
<p>Product managers become responsible for making the incoherent appear coherent. They are not empowered to change the underlying model. They are expected to manage its consequences.</p>
<p>Owning value without owning systems is advocacy, not ownership. Defining priorities without control over dependencies is performance, not strategy.</p>
<p>Over time, the organisation responds to the failure of this model by hiring more product managers, introducing more layers of prioritisation, refining portfolio management, adding frameworks and templates and vocabulary. The buffer class grows. Each addition feels like a solution. Each addition increases the distance between narrative and reality.</p>
<p>For boards, the fake product problem is a capital allocation problem. If the unit of funding does not correspond to a unit of value creation, then capital allocation is disconnected from capability.</p>
<p>A board that approves € 5 million for “Customer Engagement” believes it is investing in a capability. If Customer Engagement has no coherent boundary in the system, the € 5 million is distributed across four services maintained by three teams, filtered through dependency negotiations, and consumed by coordination. The investment produces activity. It does not compound into capability because the unit of investment does not match the unit of production.</p>
<p>This is not visible in the financial reports, because the financial reports reflect the portfolio taxonomy, not the system topology. The cost line says € 5 million for Customer Engagement. The system says that the money was spent on changes to four services, two of which primarily serve other products, coordinated through fourteen meetings, with an overhead of approximately 40\</p>
<p>When reconciliation becomes cheap, this gap becomes visible. An AI system that reads the portfolio taxonomy alongside the codebase can enumerate the discrepancy: which portfolio labels correspond to coherent system boundaries and which do not. The answer does not require an external review or a twelve-week consulting engagement. It requires pointing the AI at the artefacts and asking Peter’s question at scale.</p>
<p>The deeper issue is not which products are fake. It is that the portfolio taxonomy itself is a representation that cannot be reconciled against the system. The microservices chapter that follows examines why: because the system was decomposed around technical convenience rather than around the business processes that create value. The fake product is a symptom. The decomposition is the cause.</p>
</section>
<section id="ch-4">
<h2><a href="./?ch=4">Chapter 3: Architecture as False Abstraction</a></h2>
<p>The architecture review board meets every second Thursday. A team presents a proposal to extract a pricing calculation from a monolith into a dedicated service. The proposal is well-structured. The board evaluates it against a reference model last updated eight months ago. Forty-five minutes are spent debating which bounded context the service belongs in. In the codebase, there are sixty-three services whose boundaries follow a team structure from a reorganisation that predates the reference model by two years. The reference model describes nothing real.</p>
<p>The board grants conditional approval. The team lead nods. She will name the service to match the model, update the wiki, and build exactly what she originally proposed. The board will not check. It never does.</p>
<p>In software-dependent corporates, architecture is often presented as a source of control. Diagrams promise clarity. Reference models suggest foresight. In practice, much of this architectural activity exists to avoid accountability rather than to produce it.</p>
<p>This is not a criticism of architects. Most enterprise architects are deeply skilled, analytically rigorous, and genuinely frustrated by the gap between what they design and what the organisation builds. Architecture, in these organisations, is asked to perform a task it cannot fulfil: to impose coherence without changing the underlying structure of responsibility.</p>
<p>The distinction that matters is between advisory architecture and binding architecture.</p>
<p>Advisory architecture describes what should exist. It produces reference models, capability maps, target state diagrams, and integration views. These artefacts are reviewed, approved, and socialised. They describe how things are supposed to connect and where responsibilities are meant to lie. They can be updated without touching the system. They can be approved without consequence. They are often beautiful.</p>
<p>They rarely constrain change.</p>
<p>Binding architecture makes some changes easy and others hard. It expresses trade-offs. It embeds decisions in code, interfaces, and data contracts. It communicates through resistance, not through documentation. An engineer working within a binding architecture knows, without asking anyone, what she can change independently and what requires coordination. The architecture says: “You can change this freely. If you want to change that, you will need to talk to this team, because their contract depends on it.” This communication happens through the code, through the deployment pipeline, through the test suite, not through a document that can be ignored.</p>
<p>In software-dependent corporates, architecture is almost always advisory. Diagrams can be updated without touching the system. Principles can be asserted without enforcement. Standards can be declared without consequence.</p>
<p>The architecture review board meets monthly, evaluates proposed changes against the target state, and issues recommendations. The recommendations are advisory. The system evolves according to its own logic: deadlines, dependencies, accumulated technical decisions, and organisational pressure to ship. The architectural artefacts evolve according to theirs. The two diverge.</p>
<p>This advisory posture is not accidental. It is determined by the organisation’s own design.</p>
<p>Binding architecture would require confronting the organisational split at the heart of the system. It would require aligning ownership with behaviour, collapsing translation layers, and giving engineers authority where the work actually happens. It would require saying, out loud, that the system landscape diagram is wrong and has been wrong for two years, and that the people who approved it are the people who must now change the structure of their organisations.</p>
<p>Nobody wants to have that conversation.</p>
<p>The architecture review board exists precisely to avoid it. It provides a venue where architectural concerns can be raised without being resolved. Risks are documented. Exceptions are granted. Technical debt is acknowledged. Nothing changes, because the board has no authority to change the organisational structure that produces the debt. The board governs the symptoms while the disease progresses.</p>
<p>Architecture is used to create the appearance of control while leaving existing power structures intact. The target state diagram exists so that someone can point at it in a board presentation and say “this is where we are heading.” Whether the organisation is actually heading there is a question that the diagram cannot answer and the board does not ask.</p>
<p>The gap between the architecture the organisation describes and the architecture it operates is not a documentation failure. It is the predictable result of a structure that separates authority from consequence.</p>
<p>The people who approve architectural decisions do not maintain the systems those decisions produce. The people who maintain the systems do not have the authority to change the decisions. The architecture review board governs a fiction. The engineers govern a reality. Neither governs the other.</p>
<p>This gap accumulates. New services are built against the reference model’s terminology but the codebase’s actual structure. The reference model diverges further. New architects are hired and produce new diagrams that describe the latest aspiration rather than the current state. The previous aspirations, also unrealised, remain in the wiki. Three versions of the truth exist simultaneously. None is accurate.</p>
<p>Every incident, every debugging session, every capacity planning exercise requires engineers to hold two models simultaneously: the official model that appears in board presentations and the actual model that breaks at 3 AM. Over time, the gap widens. New engineers are onboarded using the official model and must discover the actual model through painful experience. The discovery is never documented, because documenting the divergence would require acknowledging it. Institutional knowledge becomes the ability to translate between fiction and reality. This knowledge is held by people, not by artefacts, and when those people leave, the translation capability leaves with them.</p>
<p>The accumulation is not random. It follows the path of least organisational resistance. Services are added where deployment is easy rather than where ownership is clear. Exceptions are granted when the political cost of refusal exceeds the technical cost of the exception. Architectural debt concentrates wherever the review board lacks the authority to say no. The system develops a topology that reflects the organisation’s political constraints rather than its strategic intent.</p>
<p>For boards, the advisory architecture problem means that the technology estate is ungovernable through the artefacts presented to it.</p>
<p>When a board reviews a technology strategy that references an architecture reference model, it assumes the reference model describes the system. If the reference model is advisory, the system it describes may not exist. The board is making decisions based on a description that no one has verified against reality.</p>
<p>This is the same pattern as the board narrative problem from the previous chapter, applied to technical governance. The architecture diagram is a representation. The system is the reality. The gap between the two is where the cost lives.</p>
<p>When reconciliation becomes cheap, the gap becomes visible. An AI system that reads the architecture reference model alongside the deployment topology and the codebase can enumerate every divergence: which bounded contexts have been implemented and which have not, which services share databases that the model says are independent, which integration patterns contradict the stated standards.</p>
<p>The output is not a judgement. It is an inventory. The inventory makes it impossible for the architecture review board to continue governing a fiction without acknowledging that it is a fiction. The question of whether the organisation is willing to make that acknowledgement is a governance question, not a technical one.</p>
<p>The architecture is modern in vocabulary but pre-modern in effect. Microservices are adopted, but without the design that enables autonomy. APIs are introduced, but without clear ownership. Services are deployed independently but evolve in lockstep because the decomposition followed technology boundaries rather than process boundaries. The organisation has learned the words. The next chapter examines the structural design those words actually require.</p>
</section>
<section id="ch-5">
<h2><a href="./?ch=5">Chapter 4: Microservices Without Autonomy</a></h2>
<p>A logistics company needs to add a new delivery status, “held at customs,” to the tracking flow visible to customers. The status already exists in the customs clearance system. It needs to propagate to the shipment tracking service, which feeds the customer-facing portal.</p>
<p>In a system with real boundaries and owned contracts, this is two days of work. One team adds the status to its published event contract. The consuming team reads the new event and renders it in the portal. Both teams can do this independently, on their own release schedules, with a versioned contract governing the interaction.</p>
<p>This is not what happens.</p>
<p class="continue"><a href="./?ch=5">Continue reading →</a></p>
</section>
<section id="ch-6">
<h2><a href="./?ch=6">Chapter 5: Data Centralisation and Control Illusions</a></h2>
<p>Data in a software-dependent corporate is at least two structurally different things. Most organisations treat it as one. The confusion produces coupling disguised as governance and governance disguised as control.</p>
<p>Operational data lives inside the bounded context. It serves the process the unit owns. A customer in onboarding carries different attributes, different lifecycle states, and different validation rules than a customer in billing. This is not duplication. It is precision. Each context represents the same real-world entity differently because each context serves a different process. Eliminating this difference by sharing a single canonical model does not produce consistency. It recreates the coupling that decomposition was supposed to eliminate.</p>
<p>Analytical data is a separate concern: the view of operational data the organisation needs for reporting, decision-making, and cross-cutting insight. It lives in a separate analytical domain, with its own model and governance. When finance asks a question that spans multiple units, no single operational unit can answer it.</p>
<p class="continue"><a href="./?ch=6">Continue reading →</a></p>
</section>
<section id="ch-7">
<h2><a href="./?ch=7">Chapter 6: AI as the Unforgiving Reader</a></h2>
<p>A large European telecoms operator decides to pilot an AI assistant for its technology leadership. The brief is modest: given access to the company’s strategy documents, architecture diagrams, and codebase, the assistant should produce a summary of the organisation’s technology landscape and its alignment with stated strategic priorities.</p>
<p>The CTO is supportive. The experiment is sanctioned. A small team feeds the assistant the relevant artefacts: the annual strategy deck, the technology vision document, the architecture reference model (last updated fourteen months ago), the current service catalogue, and read access to the primary code repositories.</p>
<p>The assistant produces a twelve-page synthesis. It is calm, precise, and devastating.</p>
<p class="continue"><a href="./?ch=7">Continue reading →</a></p>
</section>
<h2 class="part">When Machines Read</h2>
<section id="ch-8">
<h2><a href="./?ch=8">Chapter 7: When AI Writes the Illusion</a></h2>
<p>The quarterly board pack is due in three days. The strategy team has been preparing it for two weeks, but the technology section is still weak. The CTO’s team has submitted their update: accurate, detailed, and unreadable. Twelve pages of service dependencies, incident summaries, and migration status. The board will not engage with it.</p>
<p>So the chief of staff feeds the CTO’s update into an AI assistant, along with the company’s strategy document and last quarter’s board narrative. The prompt is simple: produce a two-page technology summary that connects the current state of the technology estate to the company’s strategic priorities, suitable for a board audience.</p>
<p>The result is impressive. The summary connects the migration of three services to a strategic priority around customer self-service. It cites a 23\</p>
<p class="continue"><a href="./?ch=8">Continue reading →</a></p>
</section>
<section id="ch-9">
<h2><a href="./?ch=9">Chapter 8: When Clarity Becomes Cheaper Than Pretence</a></h2>
<p>For most of the history of large organisations, clarity has been expensive.</p>
<p>Understanding how a system actually worked required time, access, and experience that could not be short-circuited. The people who could synthesise strategy, architecture, and operational reality were rare, expensive, and fragile: when they left, their knowledge left with them.</p>
<p>This was not a pathology. It was a rational response to a real cost structure. When synthesis is expensive, you invest in the people who can do it and tolerate the risk that any of them might leave tomorrow and take a piece of the organisation’s self-knowledge with them.</p>
<p class="continue"><a href="./?ch=9">Continue reading →</a></p>
</section>
<section id="ch-10">
<h2><a href="./?ch=10">Chapter 9: Lag Governance and Capital Mispricing</a></h2>
<p>A retail bank with a ten-year-old microservices estate invests € 1.2 million in a shared platform capability: a unified event bus that would allow its mortgage, payments, and savings teams to publish and consume domain events independently, replacing a fragile point-to-point integration layer that causes an average of three incidents per month.</p>
<p>The platform team delivers a working prototype in four months. It is technically sound. The three consuming teams are willing to migrate. The projected incident reduction is 70--80\</p>
<p>The CFO kills the investment in the annual budget review. The platform “does not show ROI in year one.” The cost is visible: € 1.2 million in engineering salaries and infrastructure. The benefit is diffuse: fewer incidents, faster change, reduced coordination overhead. None of these benefits appear as a line item in any business unit’s P\&amp;L.</p>
<p class="continue"><a href="./?ch=10">Continue reading →</a></p>
</section>
<h2 class="part">Capital Mispricing and Structural Risk</h2>
<section id="ch-11">
<h2><a href="./?ch=11">Chapter 10: The Coordination Tax and the Alignment Supply Chain</a></h2>
<p>The delivery lead’s calendar shows forty-one hours of meetings this week. She has blocked two hours on Thursday morning for “focus time.” By Tuesday afternoon, a programme steering committee has been scheduled over it.</p>
<p>She does not build anything. She does not decide anything. She translates. She takes what the product manager says the business wants, what the architect says the system can support, and what the engineering teams say they can deliver, and she reconciles them into a plan that satisfies all three. The plan is presented weekly. It is revised weekly. It has never once survived contact with the sprint.</p>
<p>Her role exists because no one in the organisation can talk directly to anyone else. Product cannot talk to engineering because they do not share a vocabulary. Architecture cannot talk to delivery because their artefacts describe different systems. Engineering cannot talk to the business because the business does not attend their meetings. She is the connective tissue.</p>
<p class="continue"><a href="./?ch=11">Continue reading →</a></p>
</section>
<section id="ch-12">
<h2><a href="./?ch=12">Chapter 11: Talent Decay as Structural Fragility</a></h2>
<p>A principal engineer at a mid-sized insurer raises a concern about a dependency that will block the roadmap. The concern is noted but not addressed. She flags a risk in an architecture review. The risk is acknowledged but deprioritised. She points out that a commitment made to the board cannot be delivered as described. She is told to find a way.</p>
<p>After enough of these exchanges, she stops. Not because she has lost the knowledge. She still sees the problems clearly, still traces the dependencies in her head, still knows which parts of the system are fragile and why. But the cost of stating what she sees has become higher than the cost of staying silent.</p>
<p>Two years later, she leaves. She takes with her an understanding of the mortgage origination process, the integration constraints, the compliance edge cases, and the failure modes of the property valuation service that no document in the organisation captures. Her replacement arrives with equivalent credentials and no context. He spends six months learning what she knew on her first day. Some of what she knew, he never learns, because it was never written down.</p>
<p class="continue"><a href="./?ch=12">Continue reading →</a></p>
</section>
<section id="ch-13">
<h2><a href="./?ch=13">Chapter 12: Operational and Regulatory Exposure</a></h2>
<p>A European insurer receives notice of a regulatory change: all policies above € 25,000 annual premium must observe a mandatory 48-hour cooling-off period before activation. During this window, payment may be collected, the policy may be cancelled without penalty, claims are not valid, and risk exposure must not be recognised on the balance sheet.</p>
<p>This is not a feature request. It is a change to the policy lifecycle.</p>
<p>The insurer’s architecture has five hundred microservices. “Activation” spans five of them: quote-to-bind, payments, policy ledger, claims eligibility, and broker commission calculation. Each publishes events consumed by dozens of downstream services. The policy ledger alone has fifty-seven consumers.</p>
<p class="continue"><a href="./?ch=13">Continue reading →</a></p>
</section>
<section id="ch-14">
<h2><a href="./?ch=14">Chapter 13: The Unit That Owns the Truth</a></h2>
<p>The payments unit has nine people. Two senior engineers, three engineers, a domain expert named Marta who spent twelve years in payments operations before joining the unit, a data analyst, a reliability engineer, and a unit lead who was previously a senior architect.</p>
<p>They own the payments process: premium collection, claims disbursement, broker commission payments, and refunds. They own the services that implement these flows, the data those services produce, and the contracts through which other units interact with them.</p>
<p>On a Wednesday morning, Marta notices that the refund process has a failure rate that has crept from 0.3\</p>
<p class="continue"><a href="./?ch=14">Continue reading →</a></p>
</section>
<h2 class="part">Structural Correction</h2>
<section id="ch-15">
<h2><a href="./?ch=15">Chapter 14: Contracts, Not Committees</a></h2>
<p>The payments unit’s contract requires consuming units to submit payment requests with fully validated customer and account data. This is structurally correct: the payments process should not validate data it does not own.</p>
<p>But the consuming units experience this differently. Motor origination finds that validating account data at point of sale adds latency that customers feel. Claims discovers that claimants who have changed banks require a re-verification step that its process definition does not accommodate. Both units face the same incentive: minimise their own validation costs and let the payments unit reject what it cannot process.</p>
<p>The payments unit tightens its contract: stricter schemas, more required fields, faster rejection of non-conforming requests. The consuming units add retry logic and error-handling layers. Within six months, the interaction has produced coordination overhead encoded in contracts rather than in meetings, but coordination overhead nonetheless. Payment failures increase. Resolution times lengthen.</p>
<p class="continue"><a href="./?ch=15">Continue reading →</a></p>
</section>
<section id="ch-16">
<h2><a href="./?ch=16">Chapter 15: Data as Outputs, Not a Shared Substrate</a></h2>
<p>In most software-dependent corporates, data is treated as a shared resource. A central data team, a common data model, a data lake or warehouse that collects everything from everywhere and makes it available to everyone. This feels disciplined. It is also the fastest way to destroy the autonomy that the previous chapters described.</p>
<p>The problem is not the aspiration. The aspiration, that the organisation should be able to answer questions that span multiple processes, is legitimate. The problem is the mechanism. When data is shared through a common substrate, every unit that reads from or writes to that substrate is coupled to every other unit that does the same. A schema change in one place propagates to every consumer. A performance issue in one pipeline affects every downstream report. The “single source of truth” becomes a single point of coupling for the organisation’s ability to change.</p>
<p>This chapter makes one argument: data should flow out of autonomous units as a published product, not pool underneath them as a shared substrate. The distinction is structural, not semantic, and it determines whether the organisation can be both autonomous and coherent.</p>
<p class="continue"><a href="./?ch=16">Continue reading →</a></p>
</section>
<section id="ch-17">
<h2><a href="./?ch=17">Chapter 16: Innovation Without Exception Budgets</a></h2>
<p>A mid-sized European insurer launches an innovation initiative around claims triage. A dedicated team of six, operating outside the normal delivery cadence, builds a machine learning model that prioritises incoming claims by predicted complexity. Governance constraints are relaxed. Architectural standards are temporarily suspended. An external AI consultancy is engaged.</p>
<p>The team delivers in four months. The model works. Claims that previously waited in a single queue are now triaged into three streams. Average resolution time for simple claims drops by 22\</p>
<p>Then the initiative ends. The team is reassigned. The model is handed to the claims operations team, which did not build it, does not understand its training data, and has no process for retraining it when the distribution of incoming claims changes.</p>
<p class="continue"><a href="./?ch=17">Continue reading →</a></p>
</section>
<section id="ch-18">
<h2><a href="./?ch=18">Chapter 17: What Changes for the CEO, CFO, CHRO, CTO, and Board</a></h2>
<p>The structural corrections described in this Part are not technology projects. They are redistributions of authority, accountability, and information. Each executive role is affected differently. This chapter describes, for each, what stops being governable by narrative, what new artefacts become decisive, what to stop rewarding, and what to authorise.</p>
<p>What stops being governable by narrative: strategy itself. In the current model, the CEO articulates strategy through documents and presentations whose connection to system behaviour is never tested. A strategy that cannot be reconciled against the organisation’s actual capabilities is not a strategy. It is an aspiration. AI reconciliation makes the gap between aspiration and capability visible, weekly, to anyone with access.</p>
<p>What becomes decisive: falsifiable commitments. A strategy document that specifies testable claims, “we will process 80\</p>
<p class="continue"><a href="./?ch=18">Continue reading →</a></p>
</section>
<section id="ch-20">
<h2><a href="./?ch=20">Conclusion</a></h2>
<p>\addtocontentstoc\protect\addvspace0.5em</p>
<p>This book has described a structural problem and a structural solution. The problem is that most software-dependent corporates cannot describe themselves clearly enough for AI to produce anything other than faster narrative. The solution is to make the organisation legible: explicit processes, owned boundaries, versioned contracts, and machine-readable artefacts that can be reconciled against the systems that run the business.</p>
<p>Between the problem and the solution lies a choice. This chapter describes that choice, why it cannot be deferred, and why it cannot be delegated.</p>
<p>Every software-dependent corporate is now investing in artificial intelligence. The investment is not optional. Boards have approved it, budgets have been allocated, and teams have been formed. The question is not whether AI will be deployed. It is what AI will be given to work with.</p>
<p>The first path uses AI to write. It generates strategy documents, board packs, status reports, and product specifications. It makes narrative production faster, cheaper, and more fluent. It threatens no existing power structure. It challenges no assumption about how the organisation operates. It produces outputs that look precise and authoritative regardless of whether the inputs are grounded in reality. The organisation becomes more confidently described without becoming better understood.</p>
<p>The second path uses AI to read. It reconciles strategy documents against codebases, architecture models against deployment topologies, investment cases against incident costs, portfolio labels against executable boundaries. It surfaces the contradictions that the organisation has been maintaining socially for years. It produces accountability by enumerating what the organisation claims and comparing it to what the system does.</p>
<p>These two paths are not complementary. They are contradictory.</p>
<p>In one path, the board pack becomes more polished each quarter. The language is sharper. The numbers are cleaner. The underlying system drifts further from what is described. In the other path, the board pack becomes shorter. Contradictions surface earlier. Some meetings become uncomfortable. Incidents decrease.</p>
<p>An organisation that uses AI to generate a fluent board pack describing a platform migration as 70\</p>
<p>The first path is easier. The second is transformative. Most organisations will try both and discover that they pull in opposite directions unless the writing is grounded in the same reality the reading inspects.</p>
<p>The choice between these paths is not a technology decision. It is a governance decision.</p>
<p>Using AI to read requires that the organisation has something for AI to read. Not strategy documents and slide decks. Machine-readable artefacts: process definitions that specify steps, decision points, and failure modes. Contracts that define how units interact. Architecture models that correspond to the actual deployment topology. Outcome metrics that are traceable to the processes that produce them.</p>
<p>These artefacts do not exist in most software-dependent corporates. Producing them requires the structural changes described in Part IV of this book: autonomous units that own processes end to end, contracts that replace committee-based coordination, data that flows as published products rather than pooling in shared substrates.</p>
<p>Without these changes, AI reads whatever the organisation gives it. If the inputs are disconnected from reality, the outputs will be disconnected from reality. The synthesis will be shallow, the contradictions will be numerous, and the reconciliation will produce noise rather than signal. The organisation will conclude that AI reconciliation “does not work yet” and retreat to the writing path.</p>
<p>This retreat is not a technology failure. It is a structural failure. The AI is capable. The organisation is not legible.</p>
<p>The temptation is to defer. To deploy AI for writing now and address the structural preconditions later. To capture the easy value first and do the hard work when the organisation is ready.</p>
<p>The argument against deferral is economic. The two paths diverge, and the divergence compounds.</p>
<p>An organisation that begins making itself legible now, that starts creating autonomous units, establishing contracts, and running AI reconciliation against real artefacts, builds structural capability that compounds over time. Each unit that becomes autonomous produces artefacts that improve the quality of the next reconciliation. Each reconciliation surfaces contradictions that, when resolved, make the organisation more coherent. Each increment of coherence reduces the cost of change, because changes happen within owned boundaries rather than across organisational fissures.</p>
<p>An organisation that defers, that uses AI for writing while the underlying structure remains unchanged, accumulates a different kind of compound effect. Each AI-generated narrative that is not reconciled against reality adds to the stock of unverified claims. Each unverified claim is a contradiction that the organisation carries silently. Each quarter of deferral means the structural deficit grows: competitors who began earlier have spent that quarter compounding the advantages of coherence.</p>
<p>The asymmetry is decisive. An organisation that adapts early and discovers the competitive pressure was slower to arrive than expected has still reduced its operating costs, improved its retention of experienced people, and built structural capability that has independent value. An organisation that defers and discovers the pressure has arrived faces a deficit that cannot be closed by purchasing the same tools, because the tools require structural preconditions that take years to establish.</p>
<p>Uncertainty about timing does not make the two options equivalent. It makes early adaptation the rational choice under any reasonable weighting of outcomes.</p>
<p>The structural changes described in this book cannot be delegated to a transformation programme, a technology team, or an external consultancy.</p>
<p>They cannot be delegated to a transformation programme because transformation programmes operate within the existing power structure. They are approved, governed, and evaluated by the same executives whose authority is redistributed by the structural change. The programme becomes a mechanism through which the existing structure absorbs the change without changing. New governance forums are created. New roles are established. New committees are formed. The remedy is metabolised by the disease.</p>
<p>They cannot be delegated to the technology team because the structural change is not a technology project. It is an organisational redesign. Service boundaries must follow process boundaries. Architecture must reflect ownership. Data must be distributed according to process ownership. These decisions require authority over the organisation, not just over the technology. A CTO who treats this as a technology programme will produce architectures that do not match the ownership model, which is how the current dysfunction was created.</p>
<p>They cannot be delegated to an external consultancy because consultancies operate under constraints that make structural recommendations undeliverable. The consultancy must produce recommendations that are acceptable to the executives who approved the engagement. Recommendations that redistribute power, collapse coordination roles, or challenge the separation between “the business” and engineering are not acceptable, because they threaten the people who must approve them. The consultancy therefore converges on more alignment, more governance, more structure layered on top of existing structure.</p>
<p>The choice must be made by the people who have the authority to redistribute power within the organisation. In every case, the structural change requires someone to say: “We will stop governing through narrative and start governing through artefact. We will accept the discomfort of seeing ourselves clearly in exchange for the capability of acting precisely.” No transformation programme can say this on behalf of the organisation. No technology team can impose it. No consultancy can recommend it in terms the current power structure will accept.</p>
<p>This means the CEO and the board.</p>
<p>The CEO must decide whether the organisation will govern through narrative or through artefact.</p>
<p>Governing through narrative means continuing to operate as the organisation does today: strategy expressed as aspiration, ownership distributed across functions, coordination managed through meetings, AI deployed for writing. This path is comfortable, familiar, and politically safe. It produces representations of progress that satisfy the board without requiring structural change.</p>
<p>Governing through artefact means committing to the structural changes described in this book: process-level ownership, autonomous units, versioned contracts, machine-readable process definitions, continuous AI reconciliation. This path is uncomfortable, politically dangerous, and structurally transformative. It produces accountability that cannot be managed through narrative.</p>
<p>The CEO cannot have both. An organisation that governs through narrative while deploying AI as a reader will produce contradictions that no amount of political management can contain. An organisation that governs through artefact while deploying AI as a writer will produce narratives that are immediately tested against reality. The two paths are incompatible.</p>
<p>The decision is not whether to invest in AI. The decision is whether to make the organisation legible enough for AI to produce structural improvement rather than faster fiction.</p>
<p>The board’s role is to ensure that the decision is made and sustained.</p>
<p>The board should demand reconciled evidence. When a strategy update arrives at the boardroom, the board should ask whether it has been tested against the system. When an investment review is presented, the board should ask whether the projected outcomes can be traced to specific process improvements. When a risk report is delivered, the board should ask whether it reflects the current state of the system or the last time someone updated a document.</p>
<p>The board should demand structural accountability. When the CEO proposes AI investment, the board should ask what structural preconditions are in place. Are processes machine-readable? Are units autonomous? Are contracts explicit? If the answers are no, the board should ask what the investment will be deployed against, and whether the expected outcomes are realistic given the organisation’s current legibility.</p>
<p>The board should sustain the decision through resistance. The structural changes described in this book will be resisted. Coordination roles will fight to preserve themselves. Finance will resist process-level cost tracking. HR will resist context-sensitive compensation. The executive team will resist the collapse of narrative authority. The board must understand that this resistance is predictable, rational, and not evidence that the change is wrong. It is evidence that the change is real.</p>
<p>This book began with a test. If an AI system attempts to synthesise an organisation from its artefacts, strategy documents, process definitions, architecture models, and codebases, will that synthesis converge on something coherent? Or will it collapse into contradiction?</p>
<p>The answer depends on whether the organisation’s processes exist as machine-readable, owned descriptions that can be parsed and reasoned about without human interpretation, or whether they exist as implicit knowledge carried in people’s heads and negotiated in meetings.</p>
<p>That is the test for any board. It can be applied before the next board meeting, before the next investment decision, before the next strategic review. It does not require a programme. It does not require a consultancy. It does not require new technology. It requires a question: can this organisation describe itself clearly enough for a machine to read it?</p>
<p>The question can be made specific. Take one critical business process: claims adjudication, mortgage origination, payment settlement, whatever process generates the most revenue or carries the most risk. Ask: does a machine-readable description of this process exist? Can it be reconciled against the code that implements it? Can the reconciliation identify contradictions without human interpretation? If the answer to any of these is no, then the organisation has identified the first unit of structural work.</p>
<p>If the answer is no, then every AI investment the organisation makes will produce faster narrative rather than structural improvement. The writing path will dominate. The gap between narrative and reality will grow. The cost of pretence will compound.</p>
<p>If the answer is yes, or if the organisation is willing to do the structural work to make the answer yes, then AI becomes what this book has described: not a productivity tool, not a content generator, but a continuous reconciliation engine that makes the organisation legible to itself. The cost of clarity falls. The cost of pretence rises. The organisation begins to see what it actually is, and the choice of what to do about it becomes real.</p>
<p>The choice cannot be deferred because the divergence is compounding. It cannot be delegated because it requires authority that no programme, team, or consultancy possesses. It cannot be avoided because AI is arriving regardless, and the question is only whether it amplifies clarity or accelerates illusion.</p>
<p>Clarity compounds into capability. Illusion compounds into fragility. AI accelerates the divergence. The difference is felt first in meetings. Then in incidents. Then in retention. Then in market position.</p>
<p>The choice is the board’s. It always was.</p>
</section>
<section id="ch-21">
<h2><a href="./?ch=21">About the Author</a></h2>
<p>Adrian McPhee has spent more than twenty years as an engineer, architect, and CTO inside software-dependent corporates across fintech, retail, and mobility, including a unicorn fintech, a leading ecommerce marketplace, and a multinational with €10 billion turnover. He has led organisations of up to a thousand people, delivered global platforms, and redirected more than €200M of product and technology investment. He watched the same structural dysfunctions repeat across every organisation he entered, and eventually learned to dismantle them.</p>
<p>As a founder and entrepreneur, he also designs and delivers platforms from scratch. It is the same discipline this book argues for: explicit structure, reconciled with reality, that a machine can actually read.</p>
<p>He now works with leadership teams to diagnose and dismantle the patterns described in this book.</p>
<p>\mbox\textbfsimpleisadvanced.com/ai-illusions-in-the-boardroom/</p>
</section>

  <div class="cta">
    <p>Read the full book in the interactive reader</p>
    <a href="./">Start reading</a>
  </div>

  <footer>
    <p>&copy; Adrian McPhee 2026 &middot;
    <a href="https://www.linkedin.com/in/adrianmcphee/" style="color: #999;">Contact</a></p>
  </footer>
</body>
</html>